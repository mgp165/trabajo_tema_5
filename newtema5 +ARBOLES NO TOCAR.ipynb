{"cells":[{"cell_type":"markdown","source":"# más que arbolitos","metadata":{"cell_id":"1160fac03cb34df48ebb9b2955d69993","formattedRanges":[],"deepnote_cell_type":"text-cell-h1"}},{"cell_type":"code","source":"!pip install xgboost\n!pip install lightgbm","metadata":{"cell_id":"4a4a2c5e73424e1a8460d30293b133fb","source_hash":"dde40f26","execution_start":1684163698530,"execution_millis":28070,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Collecting xgboost\n  Downloading xgboost-1.7.5-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting scipy\n  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting numpy\n  Downloading numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: numpy, scipy, xgboost\nSuccessfully installed numpy-1.24.3 scipy-1.10.1 xgboost-1.7.5\n\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0mCollecting lightgbm\n  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting numpy\n  Using cached numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\nCollecting wheel\n  Downloading wheel-0.40.0-py3-none-any.whl (64 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 KB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting scipy\n  Using cached scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\nCollecting scikit-learn!=0.22.0\n  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting joblib>=1.1.1\n  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 KB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting threadpoolctl>=2.0.0\n  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\nInstalling collected packages: wheel, threadpoolctl, numpy, joblib, scipy, scikit-learn, lightgbm\nSuccessfully installed joblib-1.2.0 lightgbm-3.3.5 numpy-1.24.3 scikit-learn-1.2.2 scipy-1.10.1 threadpoolctl-3.1.0 wheel-0.40.0\n\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/wheel already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/numpy-1.24.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/scipy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/scipy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/scipy-1.10.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install shap","metadata":{"cell_id":"36afc3c50de04b93be66e496c2bc3bcb","source_hash":"5d97bad","execution_start":1684164701187,"execution_millis":21922,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Collecting shap\n  Downloading shap-0.41.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (575 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.9/575.9 KB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pandas\n  Downloading pandas-2.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting scikit-learn\n  Using cached scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\nCollecting numpy\n  Using cached numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\nCollecting numba\n  Downloading numba-0.57.0-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting scipy\n  Using cached scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\nCollecting cloudpickle\n  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\nCollecting tqdm>4.25.0\n  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 KB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting packaging>20.9\n  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting slicer==0.0.7\n  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\nCollecting importlib-metadata\n  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\nCollecting llvmlite<0.41,>=0.40.0dev0\n  Downloading llvmlite-0.40.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting python-dateutil>=2.8.2\n  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 KB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tzdata>=2022.1\n  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 KB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pytz>=2020.1\n  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 KB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting threadpoolctl>=2.0.0\n  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\nCollecting joblib>=1.1.1\n  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\nCollecting six>=1.5\n  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\nCollecting zipp>=0.5\n  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\nInstalling collected packages: pytz, zipp, tzdata, tqdm, threadpoolctl, slicer, six, packaging, numpy, llvmlite, joblib, cloudpickle, scipy, python-dateutil, importlib-metadata, scikit-learn, pandas, numba, shap\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nsnowflake-snowpark-python 0.12.0 requires cloudpickle<=2.0.0,>=1.6.0, but you have cloudpickle 2.2.1 which is incompatible.\nsnowflake-connector-python 2.8.0 requires cryptography<37.0.0,>=3.1.0, but you have cryptography 38.0.4 which is incompatible.\ngoogle-cloud-bigquery 3.3.5 requires packaging<22.0.0dev,>=14.3, but you have packaging 23.1 which is incompatible.\nbotocore 1.27.95 requires urllib3<1.27,>=1.25.4, but you have urllib3 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cloudpickle-2.2.1 importlib-metadata-6.6.0 joblib-1.2.0 llvmlite-0.40.0 numba-0.57.0 numpy-1.24.3 packaging-23.1 pandas-2.0.1 python-dateutil-2.8.2 pytz-2023.3 scikit-learn-1.2.2 scipy-1.10.1 shap-0.41.0 six-1.16.0 slicer-0.0.7 threadpoolctl-3.1.0 tqdm-4.65.0 tzdata-2023.3 zipp-3.15.0\n\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/tqdm already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/threadpoolctl.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/threadpoolctl-3.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/six.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/six-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/numpy-1.24.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/joblib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/joblib-1.2.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/scipy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/scipy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/scipy-1.10.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/scikit_learn.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/scikit_learn-1.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/sklearn already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Target directory /opt/conda/lib/python3.8/site-packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error, roc_auc_score, top_k_accuracy_score, accuracy_score, roc_curve, auc, RocCurveDisplay\nimport matplotlib.pyplot as plt\nimport random as rd\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier \nimport multiprocessing\nimport time\nfrom datetime import timedelta\nfrom sklearn import tree\nfrom sklearn.datasets import make_classification\nimport plotly.graph_objects as go\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier","metadata":{"cell_id":"b295b1a28f2b4d20b9fc38df5e76bae9","source_hash":"fc14c671","execution_start":1684163762313,"execution_millis":44,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":4},{"cell_type":"code","source":"X_train = pd.read_parquet('X_train.parquet')\ny_train = pd.read_parquet('y_train.parquet')\n\nX_validation = pd.read_parquet('X_validation.parquet')\ny_validation = pd.read_parquet('y_validation.parquet')\n\nX_test = pd.read_parquet('X_test.parquet')\ny_test = pd.read_parquet('y_test.parquet')","metadata":{"cell_id":"359a1c5e8c1940c4a37ba947a91c8af7","source_hash":"62d96045","execution_start":1684163765469,"execution_millis":455,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## bagging","metadata":{"cell_id":"88a4a801b2084310ba7f4631aee3a92c","formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"### random forest","metadata":{"cell_id":"7529e1996a0a47cd80e67cbe91e4e783","formattedRanges":[],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"metrics = {}\nfor n_estimators in [3, 5, 10, 15, 30, 50, 100, 250]:\n    for max_depth in [4, 8, 12, 16, 20]:\n        start_time = time.time()\n        model = RandomForestClassifier(n_estimators = n_estimators, max_depth = max_depth, max_features = 'sqrt')\n        model.fit(X_train, y_train);\n        \n        train_pred = model.predict_proba(X_train)[:, 1]\n        test_pred = model.predict_proba(X_validation)[:, 1]\n\n        metrics['RF_'+ str(n_estimators)+'_'+str(max_depth)] = {\n            'Train_Gini': 2*roc_auc_score(y_train, train_pred)-1,\n            'Test_Gini': 2*roc_auc_score(y_validation, test_pred)-1,\n            'Run_Time': time.time() - start_time\n            }\n\nmetrics_RF = pd.DataFrame.from_dict(metrics, orient='index',columns=['Run_Time', 'Train_Gini', 'Test_Gini'])\nmetrics_RF['delta'] = (metrics_RF.Test_Gini - metrics_RF.Train_Gini) / metrics_RF.Train_Gini\nmetrics_RF","metadata":{"cell_id":"d2f036dfe8554b6f9bdc5fddcbb65cd7","source_hash":"63c59c0c","execution_start":1684163987753,"execution_millis":41612,"deepnote_table_state":{"sortBy":[{"id":"delta","type":"asc"}],"filters":[],"pageSize":10,"pageIndex":2},"deepnote_table_invalid":false,"deepnote_table_loading":false,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n/tmp/ipykernel_88/3256116642.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train, y_train);\n","output_type":"stream"},{"output_type":"execute_result","execution_count":8,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":4,"row_count":40,"columns":[{"name":"Run_Time","dtype":"float64","stats":{"unique_count":40,"nan_count":0,"min":"0.06113481521606445","max":"6.195659875869751","histogram":[{"bin_start":0.06113481521606445,"bin_end":0.6745873212814331,"count":24},{"bin_start":0.6745873212814331,"bin_end":1.2880398273468017,"count":7},{"bin_start":1.2880398273468017,"bin_end":1.9014923334121703,"count":2},{"bin_start":1.9014923334121703,"bin_end":2.514944839477539,"count":3},{"bin_start":2.514944839477539,"bin_end":3.1283973455429077,"count":0},{"bin_start":3.1283973455429077,"bin_end":3.741849851608276,"count":1},{"bin_start":3.741849851608276,"bin_end":4.3553023576736445,"count":0},{"bin_start":4.3553023576736445,"bin_end":4.968754863739013,"count":1},{"bin_start":4.968754863739013,"bin_end":5.582207369804382,"count":1},{"bin_start":5.582207369804382,"bin_end":6.195659875869751,"count":1}]}},{"name":"Train_Gini","dtype":"float64","stats":{"unique_count":40,"nan_count":0,"min":"0.6291961006175391","max":"0.9898316360915829","histogram":[{"bin_start":0.6291961006175391,"bin_end":0.6652596541649435,"count":2},{"bin_start":0.6652596541649435,"bin_end":0.7013232077123478,"count":0},{"bin_start":0.7013232077123478,"bin_end":0.7373867612597522,"count":5},{"bin_start":0.7373867612597522,"bin_end":0.7734503148071565,"count":2},{"bin_start":0.7734503148071565,"bin_end":0.809513868354561,"count":1},{"bin_start":0.809513868354561,"bin_end":0.8455774219019654,"count":6},{"bin_start":0.8455774219019654,"bin_end":0.8816409754493697,"count":2},{"bin_start":0.8816409754493697,"bin_end":0.9177045289967741,"count":6},{"bin_start":0.9177045289967741,"bin_end":0.9537680825441786,"count":3},{"bin_start":0.9537680825441786,"bin_end":0.9898316360915829,"count":13}]}},{"name":"Test_Gini","dtype":"float64","stats":{"unique_count":40,"nan_count":0,"min":"0.5854320120469754","max":"0.892249169685627","histogram":[{"bin_start":0.5854320120469754,"bin_end":0.6161137278108405,"count":2},{"bin_start":0.6161137278108405,"bin_end":0.6467954435747056,"count":0},{"bin_start":0.6467954435747056,"bin_end":0.6774771593385709,"count":2},{"bin_start":0.6774771593385709,"bin_end":0.708158875102436,"count":4},{"bin_start":0.708158875102436,"bin_end":0.7388405908663012,"count":1},{"bin_start":0.7388405908663012,"bin_end":0.7695223066301663,"count":1},{"bin_start":0.7695223066301663,"bin_end":0.8002040223940314,"count":4},{"bin_start":0.8002040223940314,"bin_end":0.8308857381578967,"count":5},{"bin_start":0.8308857381578967,"bin_end":0.8615674539217617,"count":10},{"bin_start":0.8615674539217617,"bin_end":0.892249169685627,"count":11}]}},{"name":"delta","dtype":"float64","stats":{"unique_count":40,"nan_count":0,"min":"-0.1525371136262294","max":"-0.04080027479840804","histogram":[{"bin_start":-0.1525371136262294,"bin_end":-0.14136342974344726,"count":1},{"bin_start":-0.14136342974344726,"bin_end":-0.13018974586066512,"count":0},{"bin_start":-0.13018974586066512,"bin_end":-0.11901606197788299,"count":1},{"bin_start":-0.11901606197788299,"bin_end":-0.10784237809510086,"count":2},{"bin_start":-0.10784237809510086,"bin_end":-0.09666869421231872,"count":4},{"bin_start":-0.09666869421231872,"bin_end":-0.08549501032953657,"count":6},{"bin_start":-0.08549501032953657,"bin_end":-0.07432132644675445,"count":3},{"bin_start":-0.07432132644675445,"bin_end":-0.0631476425639723,"count":7},{"bin_start":-0.0631476425639723,"bin_end":-0.05197395868119016,"count":9},{"bin_start":-0.05197395868119016,"bin_end":-0.04080027479840804,"count":7}]}},{"name":"_deepnote_index_column","dtype":"object"}],"rows":[{"Run_Time":"0.28580689430236816","Train_Gini":"0.902071904275056","Test_Gini":"0.8417630087930736","delta":"-0.06685597367146603","_deepnote_index_column":"RF_15_12"},{"Run_Time":"0.23438549041748047","Train_Gini":"0.899557200484022","Test_Gini":"0.8397869327521537","delta":"-0.06644409905196459","_deepnote_index_column":"RF_10_12"},{"Run_Time":"0.9478659629821777","Train_Gini":"0.9114090579935485","Test_Gini":"0.8528405491701667","delta":"-0.0642614952196321","_deepnote_index_column":"RF_50_12"},{"Run_Time":"0.56903076171875","Train_Gini":"0.9114868477858022","Test_Gini":"0.8537214601986338","delta":"-0.06337489973387217","_deepnote_index_column":"RF_30_12"},{"Run_Time":"1.8277499675750732","Train_Gini":"0.9132940529070972","Test_Gini":"0.8568422555042907","delta":"-0.061811195663779184","_deepnote_index_column":"RF_100_12"},{"Run_Time":"4.572807788848877","Train_Gini":"0.9128600623904102","Test_Gini":"0.8570237940595837","delta":"-0.06116629550493633","_deepnote_index_column":"RF_250_12"},{"Run_Time":"0.11782050132751465","Train_Gini":"0.7086332266578796","Test_Gini":"0.667441894030878","delta":"-0.05812785948701841","_deepnote_index_column":"RF_10_4"},{"Run_Time":"0.23859763145446777","Train_Gini":"0.8218708830567154","Test_Gini":"0.7742872767452638","delta":"-0.057896693133205945","_deepnote_index_column":"RF_15_8"},{"Run_Time":"0.06750249862670898","Train_Gini":"0.7568594499067274","Test_Gini":"0.713227136485882","delta":"-0.057649162504640035","_deepnote_index_column":"RF_3_8"},{"Run_Time":"0.3168025016784668","Train_Gini":"0.7152847048930682","Test_Gini":"0.6745642353009096","delta":"-0.05692903722615753","_deepnote_index_column":"RF_30_4"}]},"text/plain":"           Run_Time  Train_Gini  Test_Gini     delta\nRF_3_4     0.061135    0.660188   0.609807 -0.076313\nRF_3_8     0.067502    0.756859   0.713227 -0.057649\nRF_3_12    0.073014    0.857953   0.797249 -0.070754\nRF_3_16    0.094496    0.931354   0.841745 -0.096213\nRF_3_20    0.098831    0.963831   0.816811 -0.152537\nRF_5_4     0.082023    0.629196   0.585432 -0.069556\nRF_5_8     0.088398    0.807223   0.768955 -0.047407\nRF_5_12    0.107298    0.879628   0.816809 -0.071416\nRF_5_16    0.126822    0.945594   0.857910 -0.092729\nRF_5_20    0.146993    0.977082   0.858598 -0.121264\nRF_10_4    0.117821    0.708633   0.667442 -0.058128\nRF_10_8    0.164716    0.818903   0.774917 -0.053713\nRF_10_12   0.234385    0.899557   0.839787 -0.066444\nRF_10_16   0.231072    0.951288   0.860659 -0.095270\nRF_10_20   0.267266    0.983816   0.869854 -0.115837\nRF_15_4    0.170861    0.736337   0.695105 -0.055997\nRF_15_8    0.238598    0.821871   0.774287 -0.057897\nRF_15_12   0.285807    0.902072   0.841763 -0.066856\nRF_15_16   0.335349    0.957042   0.874997 -0.085728\nRF_15_20   0.375123    0.985963   0.876778 -0.110739\nRF_30_4    0.316803    0.715285   0.674564 -0.056929\nRF_30_8    0.434315    0.835576   0.795647 -0.047786\nRF_30_12   0.569031    0.911487   0.853721 -0.063375\nRF_30_16   0.684967    0.963281   0.879225 -0.087260\nRF_30_20   0.746401    0.988690   0.887911 -0.101932\nRF_50_4    0.495701    0.731695   0.693482 -0.052225\nRF_50_8    0.727695    0.841029   0.804695 -0.043202\nRF_50_12   0.947866    0.911409   0.852841 -0.064261\nRF_50_16   1.087414    0.964786   0.880956 -0.086890\nRF_50_20   1.248180    0.989832   0.887123 -0.103764\nRF_100_4   0.969708    0.739639   0.706311 -0.045060\nRF_100_8   1.394019    0.838325   0.804121 -0.040800\nRF_100_12  1.827750    0.913294   0.856842 -0.061811\nRF_100_16  2.170380    0.964646   0.882378 -0.085283\nRF_100_20  2.428640    0.989207   0.889818 -0.100473\nRF_250_4   2.439889    0.730761   0.696747 -0.046546\nRF_250_8   3.506880    0.842255   0.806454 -0.042506\nRF_250_12  4.572808    0.912860   0.857024 -0.061166\nRF_250_16  5.452392    0.964571   0.883830 -0.083706\nRF_250_20  6.195660    0.989759   0.892249 -0.098519","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Run_Time</th>\n      <th>Train_Gini</th>\n      <th>Test_Gini</th>\n      <th>delta</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>RF_3_4</th>\n      <td>0.061135</td>\n      <td>0.660188</td>\n      <td>0.609807</td>\n      <td>-0.076313</td>\n    </tr>\n    <tr>\n      <th>RF_3_8</th>\n      <td>0.067502</td>\n      <td>0.756859</td>\n      <td>0.713227</td>\n      <td>-0.057649</td>\n    </tr>\n    <tr>\n      <th>RF_3_12</th>\n      <td>0.073014</td>\n      <td>0.857953</td>\n      <td>0.797249</td>\n      <td>-0.070754</td>\n    </tr>\n    <tr>\n      <th>RF_3_16</th>\n      <td>0.094496</td>\n      <td>0.931354</td>\n      <td>0.841745</td>\n      <td>-0.096213</td>\n    </tr>\n    <tr>\n      <th>RF_3_20</th>\n      <td>0.098831</td>\n      <td>0.963831</td>\n      <td>0.816811</td>\n      <td>-0.152537</td>\n    </tr>\n    <tr>\n      <th>RF_5_4</th>\n      <td>0.082023</td>\n      <td>0.629196</td>\n      <td>0.585432</td>\n      <td>-0.069556</td>\n    </tr>\n    <tr>\n      <th>RF_5_8</th>\n      <td>0.088398</td>\n      <td>0.807223</td>\n      <td>0.768955</td>\n      <td>-0.047407</td>\n    </tr>\n    <tr>\n      <th>RF_5_12</th>\n      <td>0.107298</td>\n      <td>0.879628</td>\n      <td>0.816809</td>\n      <td>-0.071416</td>\n    </tr>\n    <tr>\n      <th>RF_5_16</th>\n      <td>0.126822</td>\n      <td>0.945594</td>\n      <td>0.857910</td>\n      <td>-0.092729</td>\n    </tr>\n    <tr>\n      <th>RF_5_20</th>\n      <td>0.146993</td>\n      <td>0.977082</td>\n      <td>0.858598</td>\n      <td>-0.121264</td>\n    </tr>\n    <tr>\n      <th>RF_10_4</th>\n      <td>0.117821</td>\n      <td>0.708633</td>\n      <td>0.667442</td>\n      <td>-0.058128</td>\n    </tr>\n    <tr>\n      <th>RF_10_8</th>\n      <td>0.164716</td>\n      <td>0.818903</td>\n      <td>0.774917</td>\n      <td>-0.053713</td>\n    </tr>\n    <tr>\n      <th>RF_10_12</th>\n      <td>0.234385</td>\n      <td>0.899557</td>\n      <td>0.839787</td>\n      <td>-0.066444</td>\n    </tr>\n    <tr>\n      <th>RF_10_16</th>\n      <td>0.231072</td>\n      <td>0.951288</td>\n      <td>0.860659</td>\n      <td>-0.095270</td>\n    </tr>\n    <tr>\n      <th>RF_10_20</th>\n      <td>0.267266</td>\n      <td>0.983816</td>\n      <td>0.869854</td>\n      <td>-0.115837</td>\n    </tr>\n    <tr>\n      <th>RF_15_4</th>\n      <td>0.170861</td>\n      <td>0.736337</td>\n      <td>0.695105</td>\n      <td>-0.055997</td>\n    </tr>\n    <tr>\n      <th>RF_15_8</th>\n      <td>0.238598</td>\n      <td>0.821871</td>\n      <td>0.774287</td>\n      <td>-0.057897</td>\n    </tr>\n    <tr>\n      <th>RF_15_12</th>\n      <td>0.285807</td>\n      <td>0.902072</td>\n      <td>0.841763</td>\n      <td>-0.066856</td>\n    </tr>\n    <tr>\n      <th>RF_15_16</th>\n      <td>0.335349</td>\n      <td>0.957042</td>\n      <td>0.874997</td>\n      <td>-0.085728</td>\n    </tr>\n    <tr>\n      <th>RF_15_20</th>\n      <td>0.375123</td>\n      <td>0.985963</td>\n      <td>0.876778</td>\n      <td>-0.110739</td>\n    </tr>\n    <tr>\n      <th>RF_30_4</th>\n      <td>0.316803</td>\n      <td>0.715285</td>\n      <td>0.674564</td>\n      <td>-0.056929</td>\n    </tr>\n    <tr>\n      <th>RF_30_8</th>\n      <td>0.434315</td>\n      <td>0.835576</td>\n      <td>0.795647</td>\n      <td>-0.047786</td>\n    </tr>\n    <tr>\n      <th>RF_30_12</th>\n      <td>0.569031</td>\n      <td>0.911487</td>\n      <td>0.853721</td>\n      <td>-0.063375</td>\n    </tr>\n    <tr>\n      <th>RF_30_16</th>\n      <td>0.684967</td>\n      <td>0.963281</td>\n      <td>0.879225</td>\n      <td>-0.087260</td>\n    </tr>\n    <tr>\n      <th>RF_30_20</th>\n      <td>0.746401</td>\n      <td>0.988690</td>\n      <td>0.887911</td>\n      <td>-0.101932</td>\n    </tr>\n    <tr>\n      <th>RF_50_4</th>\n      <td>0.495701</td>\n      <td>0.731695</td>\n      <td>0.693482</td>\n      <td>-0.052225</td>\n    </tr>\n    <tr>\n      <th>RF_50_8</th>\n      <td>0.727695</td>\n      <td>0.841029</td>\n      <td>0.804695</td>\n      <td>-0.043202</td>\n    </tr>\n    <tr>\n      <th>RF_50_12</th>\n      <td>0.947866</td>\n      <td>0.911409</td>\n      <td>0.852841</td>\n      <td>-0.064261</td>\n    </tr>\n    <tr>\n      <th>RF_50_16</th>\n      <td>1.087414</td>\n      <td>0.964786</td>\n      <td>0.880956</td>\n      <td>-0.086890</td>\n    </tr>\n    <tr>\n      <th>RF_50_20</th>\n      <td>1.248180</td>\n      <td>0.989832</td>\n      <td>0.887123</td>\n      <td>-0.103764</td>\n    </tr>\n    <tr>\n      <th>RF_100_4</th>\n      <td>0.969708</td>\n      <td>0.739639</td>\n      <td>0.706311</td>\n      <td>-0.045060</td>\n    </tr>\n    <tr>\n      <th>RF_100_8</th>\n      <td>1.394019</td>\n      <td>0.838325</td>\n      <td>0.804121</td>\n      <td>-0.040800</td>\n    </tr>\n    <tr>\n      <th>RF_100_12</th>\n      <td>1.827750</td>\n      <td>0.913294</td>\n      <td>0.856842</td>\n      <td>-0.061811</td>\n    </tr>\n    <tr>\n      <th>RF_100_16</th>\n      <td>2.170380</td>\n      <td>0.964646</td>\n      <td>0.882378</td>\n      <td>-0.085283</td>\n    </tr>\n    <tr>\n      <th>RF_100_20</th>\n      <td>2.428640</td>\n      <td>0.989207</td>\n      <td>0.889818</td>\n      <td>-0.100473</td>\n    </tr>\n    <tr>\n      <th>RF_250_4</th>\n      <td>2.439889</td>\n      <td>0.730761</td>\n      <td>0.696747</td>\n      <td>-0.046546</td>\n    </tr>\n    <tr>\n      <th>RF_250_8</th>\n      <td>3.506880</td>\n      <td>0.842255</td>\n      <td>0.806454</td>\n      <td>-0.042506</td>\n    </tr>\n    <tr>\n      <th>RF_250_12</th>\n      <td>4.572808</td>\n      <td>0.912860</td>\n      <td>0.857024</td>\n      <td>-0.061166</td>\n    </tr>\n    <tr>\n      <th>RF_250_16</th>\n      <td>5.452392</td>\n      <td>0.964571</td>\n      <td>0.883830</td>\n      <td>-0.083706</td>\n    </tr>\n    <tr>\n      <th>RF_250_20</th>\n      <td>6.195660</td>\n      <td>0.989759</td>\n      <td>0.892249</td>\n      <td>-0.098519</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"los de max depth 12 son muy buenos, como los cart anteriores incluso un poco mejores","metadata":{"cell_id":"99588e59599148bd94b0334a99aeec37","formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"el de numero arboles 30 y profundidad maxima 12 lo estudiamos luego con shap","metadata":{"cell_id":"aab6d4f590aa46c8a53e34b635a4f193","formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"### extra trees","metadata":{"cell_id":"d7d38a0328d64d659b33bc8a980f76f7","formattedRanges":[],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"metrics = {}\nfor n_estimators in [3, 5, 10, 15, 30, 50, 100, 250]:\n    for max_depth in [4, 8, 12, 16, 20]:\n        start_time = time.time()\n        model = ExtraTreesClassifier(n_estimators = n_estimators, max_depth = max_depth, max_features = 'sqrt')\n        model.fit(X_train,y_train);\n        \n        train_pred = model.predict_proba(X_train)[:, 1]\n        test_pred = model.predict_proba(X_validation)[:, 1]\n\n        metrics['ET_'+ str(n_estimators)+'_'+str(max_depth)] = {\n            'Train_Gini': 2*roc_auc_score(y_train, train_pred)-1,\n            'Test_Gini': 2*roc_auc_score(y_validation, test_pred)-1,\n            'Run_Time': time.time() - start_time\n            }\n\nmetrics_ET = pd.DataFrame.from_dict(metrics, orient='index',columns=['Run_Time', 'Train_Gini', 'Test_Gini'])\nmetrics_ET['delta'] = (metrics_ET.Test_Gini - metrics_ET.Train_Gini) / metrics_ET.Train_Gini\nmetrics_ET","metadata":{"cell_id":"2fe4fab75096453b937ffe462fca6e6c","source_hash":"656598c0","execution_start":1684163925913,"execution_millis":33747,"deepnote_table_state":{"sortBy":[{"id":"delta","type":"asc"}],"filters":[],"pageSize":10,"pageIndex":0},"deepnote_table_loading":false,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n/tmp/ipykernel_88/3026725649.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(X_train,y_train);\n","output_type":"stream"},{"output_type":"execute_result","execution_count":7,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":4,"row_count":40,"columns":[{"name":"Run_Time","dtype":"float64","stats":{"unique_count":40,"nan_count":0,"min":"0.050406455993652344","max":"5.558471441268921","histogram":[{"bin_start":0.050406455993652344,"bin_end":0.6012129545211792,"count":26},{"bin_start":0.6012129545211792,"bin_end":1.152019453048706,"count":6},{"bin_start":1.152019453048706,"bin_end":1.7028259515762327,"count":1},{"bin_start":1.7028259515762327,"bin_end":2.2536324501037597,"count":3},{"bin_start":2.2536324501037597,"bin_end":2.8044389486312866,"count":1},{"bin_start":2.8044389486312866,"bin_end":3.355245447158813,"count":0},{"bin_start":3.355245447158813,"bin_end":3.90605194568634,"count":1},{"bin_start":3.90605194568634,"bin_end":4.456858444213867,"count":1},{"bin_start":4.456858444213867,"bin_end":5.0076649427413935,"count":0},{"bin_start":5.0076649427413935,"bin_end":5.558471441268921,"count":1}]}},{"name":"Train_Gini","dtype":"float64","stats":{"unique_count":40,"nan_count":0,"min":"0.5552326292316931","max":"0.9690239286900231","histogram":[{"bin_start":0.5552326292316931,"bin_end":0.5966117591775262,"count":1},{"bin_start":0.5966117591775262,"bin_end":0.6379908891233591,"count":0},{"bin_start":0.6379908891233591,"bin_end":0.6793700190691921,"count":2},{"bin_start":0.6793700190691921,"bin_end":0.7207491490150251,"count":4},{"bin_start":0.7207491490150251,"bin_end":0.7621282789608581,"count":7},{"bin_start":0.7621282789608581,"bin_end":0.8035074089066911,"count":4},{"bin_start":0.8035074089066911,"bin_end":0.8448865388525242,"count":6},{"bin_start":0.8448865388525242,"bin_end":0.8862656687983571,"count":2},{"bin_start":0.8862656687983571,"bin_end":0.92764479874419,"count":6},{"bin_start":0.92764479874419,"bin_end":0.9690239286900231,"count":8}]}},{"name":"Test_Gini","dtype":"float64","stats":{"unique_count":40,"nan_count":0,"min":"0.5619248539432513","max":"0.8634501306211602","histogram":[{"bin_start":0.5619248539432513,"bin_end":0.5920773816110422,"count":1},{"bin_start":0.5920773816110422,"bin_end":0.622229909278833,"count":0},{"bin_start":0.622229909278833,"bin_end":0.652382436946624,"count":1},{"bin_start":0.652382436946624,"bin_end":0.6825349646144149,"count":3},{"bin_start":0.6825349646144149,"bin_end":0.7126874922822057,"count":6},{"bin_start":0.7126874922822057,"bin_end":0.7428400199499966,"count":4},{"bin_start":0.7428400199499966,"bin_end":0.7729925476177875,"count":3},{"bin_start":0.7729925476177875,"bin_end":0.8031450752855784,"count":8},{"bin_start":0.8031450752855784,"bin_end":0.8332976029533692,"count":8},{"bin_start":0.8332976029533692,"bin_end":0.8634501306211602,"count":6}]}},{"name":"delta","dtype":"float64","stats":{"unique_count":40,"nan_count":0,"min":"-0.140291060998842","max":"0.012053010502676294","histogram":[{"bin_start":-0.140291060998842,"bin_end":-0.12505665384869016,"count":1},{"bin_start":-0.12505665384869016,"bin_end":-0.10982224669853835,"count":3},{"bin_start":-0.10982224669853835,"bin_end":-0.09458783954838651,"count":7},{"bin_start":-0.09458783954838651,"bin_end":-0.07935343239823468,"count":4},{"bin_start":-0.07935343239823468,"bin_end":-0.06411902524808286,"count":2},{"bin_start":-0.06411902524808286,"bin_end":-0.048884618097931015,"count":6},{"bin_start":-0.048884618097931015,"bin_end":-0.03365021094777919,"count":8},{"bin_start":-0.03365021094777919,"bin_end":-0.01841580379762736,"count":8},{"bin_start":-0.01841580379762736,"bin_end":-0.0031813966474755206,"count":0},{"bin_start":-0.0031813966474755206,"bin_end":0.012053010502676294,"count":1}]}},{"name":"_deepnote_index_column","dtype":"object"}],"rows":[{"Run_Time":"0.09173965454101562","Train_Gini":"0.9354335267894323","Test_Gini":"0.8042005648222541","delta":"-0.140291060998842","_deepnote_index_column":"ET_3_20"},{"Run_Time":"0.1256701946258545","Train_Gini":"0.9429258243706675","Test_Gini":"0.825633500598981","delta":"-0.12439188824844243","_deepnote_index_column":"ET_5_20"},{"Run_Time":"0.6263449192047119","Train_Gini":"0.9629223836962955","Test_Gini":"0.8562846498887835","delta":"-0.11074385185457","_deepnote_index_column":"ET_30_20"},{"Run_Time":"0.32463622093200684","Train_Gini":"0.9580554588699384","Test_Gini":"0.8520585862765193","delta":"-0.1106375122776778","_deepnote_index_column":"ET_15_20"},{"Run_Time":"0.22632503509521484","Train_Gini":"0.9571393229436604","Test_Gini":"0.8521086216380487","delta":"-0.10973397371512457","_deepnote_index_column":"ET_10_20"},{"Run_Time":"1.0637569427490234","Train_Gini":"0.9690239286900231","Test_Gini":"0.8627895676271211","delta":"-0.10963027631992028","_deepnote_index_column":"ET_50_20"},{"Run_Time":"5.558471441268921","Train_Gini":"0.9678560416023361","Test_Gini":"0.8634501306211602","delta":"-0.10787338869975589","_deepnote_index_column":"ET_250_20"},{"Run_Time":"2.039555549621582","Train_Gini":"0.965089128378253","Test_Gini":"0.8615694745805929","delta":"-0.10726434559636557","_deepnote_index_column":"ET_100_20"},{"Run_Time":"0.07928299903869629","Train_Gini":"0.8742951800371055","Test_Gini":"0.7872975933311843","delta":"-0.09950596628272497","_deepnote_index_column":"ET_3_16"},{"Run_Time":"0.2047731876373291","Train_Gini":"0.8958297353554023","Test_Gini":"0.8086979740489673","delta":"-0.09726375210336963","_deepnote_index_column":"ET_10_16"}]},"text/plain":"           Run_Time  Train_Gini  Test_Gini     delta\nET_3_4     0.051271    0.555233   0.561925  0.012053\nET_3_8     0.050406    0.693201   0.673318 -0.028684\nET_3_12    0.073818    0.749193   0.689920 -0.079116\nET_3_16    0.079283    0.874295   0.787298 -0.099506\nET_3_20    0.091740    0.935434   0.804201 -0.140291\nET_5_4     0.064839    0.676983   0.655602 -0.031582\nET_5_8     0.073164    0.688277   0.666041 -0.032306\nET_5_12    0.088329    0.800227   0.752188 -0.060032\nET_5_16    0.107989    0.884039   0.798913 -0.096292\nET_5_20    0.125670    0.942926   0.825634 -0.124392\nET_10_4    0.092548    0.662316   0.639733 -0.034097\nET_10_8    0.135945    0.739760   0.707635 -0.043427\nET_10_12   0.169798    0.812451   0.773445 -0.048010\nET_10_16   0.204773    0.895830   0.808698 -0.097264\nET_10_20   0.226325    0.957139   0.852109 -0.109734\nET_15_4    0.146695    0.713768   0.698521 -0.021361\nET_15_8    0.190427    0.754608   0.723985 -0.040582\nET_15_12   0.229378    0.827642   0.777755 -0.060276\nET_15_16   0.300684    0.905096   0.828941 -0.084140\nET_15_20   0.324636    0.958055   0.852059 -0.110638\nET_30_4    0.242934    0.734571   0.713883 -0.028163\nET_30_8    0.362142    0.762046   0.736045 -0.034120\nET_30_12   0.431340    0.828973   0.778527 -0.060853\nET_30_16   0.523057    0.896837   0.826041 -0.078940\nET_30_20   0.626345    0.962922   0.856285 -0.110744\nET_50_4    0.405657    0.732375   0.709612 -0.031081\nET_50_8    0.565447    0.765167   0.734255 -0.040399\nET_50_12   0.716370    0.829453   0.784921 -0.053688\nET_50_16   0.883430    0.896631   0.818996 -0.086585\nET_50_20   1.063757    0.969024   0.862790 -0.109630\nET_100_4   0.795927    0.716622   0.693258 -0.032603\nET_100_8   1.087413    0.772581   0.742928 -0.038381\nET_100_12  1.433501    0.829148   0.782651 -0.056079\nET_100_16  1.727899    0.902929   0.827694 -0.083323\nET_100_20  2.039556    0.965089   0.861569 -0.107264\nET_250_4   1.863411    0.726130   0.706487 -0.027052\nET_250_8   2.659302    0.772875   0.745876 -0.034933\nET_250_12  3.466692    0.835571   0.789267 -0.055416\nET_250_16  4.430279    0.904650   0.830463 -0.082007\nET_250_20  5.558471    0.967856   0.863450 -0.107873","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Run_Time</th>\n      <th>Train_Gini</th>\n      <th>Test_Gini</th>\n      <th>delta</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ET_3_4</th>\n      <td>0.051271</td>\n      <td>0.555233</td>\n      <td>0.561925</td>\n      <td>0.012053</td>\n    </tr>\n    <tr>\n      <th>ET_3_8</th>\n      <td>0.050406</td>\n      <td>0.693201</td>\n      <td>0.673318</td>\n      <td>-0.028684</td>\n    </tr>\n    <tr>\n      <th>ET_3_12</th>\n      <td>0.073818</td>\n      <td>0.749193</td>\n      <td>0.689920</td>\n      <td>-0.079116</td>\n    </tr>\n    <tr>\n      <th>ET_3_16</th>\n      <td>0.079283</td>\n      <td>0.874295</td>\n      <td>0.787298</td>\n      <td>-0.099506</td>\n    </tr>\n    <tr>\n      <th>ET_3_20</th>\n      <td>0.091740</td>\n      <td>0.935434</td>\n      <td>0.804201</td>\n      <td>-0.140291</td>\n    </tr>\n    <tr>\n      <th>ET_5_4</th>\n      <td>0.064839</td>\n      <td>0.676983</td>\n      <td>0.655602</td>\n      <td>-0.031582</td>\n    </tr>\n    <tr>\n      <th>ET_5_8</th>\n      <td>0.073164</td>\n      <td>0.688277</td>\n      <td>0.666041</td>\n      <td>-0.032306</td>\n    </tr>\n    <tr>\n      <th>ET_5_12</th>\n      <td>0.088329</td>\n      <td>0.800227</td>\n      <td>0.752188</td>\n      <td>-0.060032</td>\n    </tr>\n    <tr>\n      <th>ET_5_16</th>\n      <td>0.107989</td>\n      <td>0.884039</td>\n      <td>0.798913</td>\n      <td>-0.096292</td>\n    </tr>\n    <tr>\n      <th>ET_5_20</th>\n      <td>0.125670</td>\n      <td>0.942926</td>\n      <td>0.825634</td>\n      <td>-0.124392</td>\n    </tr>\n    <tr>\n      <th>ET_10_4</th>\n      <td>0.092548</td>\n      <td>0.662316</td>\n      <td>0.639733</td>\n      <td>-0.034097</td>\n    </tr>\n    <tr>\n      <th>ET_10_8</th>\n      <td>0.135945</td>\n      <td>0.739760</td>\n      <td>0.707635</td>\n      <td>-0.043427</td>\n    </tr>\n    <tr>\n      <th>ET_10_12</th>\n      <td>0.169798</td>\n      <td>0.812451</td>\n      <td>0.773445</td>\n      <td>-0.048010</td>\n    </tr>\n    <tr>\n      <th>ET_10_16</th>\n      <td>0.204773</td>\n      <td>0.895830</td>\n      <td>0.808698</td>\n      <td>-0.097264</td>\n    </tr>\n    <tr>\n      <th>ET_10_20</th>\n      <td>0.226325</td>\n      <td>0.957139</td>\n      <td>0.852109</td>\n      <td>-0.109734</td>\n    </tr>\n    <tr>\n      <th>ET_15_4</th>\n      <td>0.146695</td>\n      <td>0.713768</td>\n      <td>0.698521</td>\n      <td>-0.021361</td>\n    </tr>\n    <tr>\n      <th>ET_15_8</th>\n      <td>0.190427</td>\n      <td>0.754608</td>\n      <td>0.723985</td>\n      <td>-0.040582</td>\n    </tr>\n    <tr>\n      <th>ET_15_12</th>\n      <td>0.229378</td>\n      <td>0.827642</td>\n      <td>0.777755</td>\n      <td>-0.060276</td>\n    </tr>\n    <tr>\n      <th>ET_15_16</th>\n      <td>0.300684</td>\n      <td>0.905096</td>\n      <td>0.828941</td>\n      <td>-0.084140</td>\n    </tr>\n    <tr>\n      <th>ET_15_20</th>\n      <td>0.324636</td>\n      <td>0.958055</td>\n      <td>0.852059</td>\n      <td>-0.110638</td>\n    </tr>\n    <tr>\n      <th>ET_30_4</th>\n      <td>0.242934</td>\n      <td>0.734571</td>\n      <td>0.713883</td>\n      <td>-0.028163</td>\n    </tr>\n    <tr>\n      <th>ET_30_8</th>\n      <td>0.362142</td>\n      <td>0.762046</td>\n      <td>0.736045</td>\n      <td>-0.034120</td>\n    </tr>\n    <tr>\n      <th>ET_30_12</th>\n      <td>0.431340</td>\n      <td>0.828973</td>\n      <td>0.778527</td>\n      <td>-0.060853</td>\n    </tr>\n    <tr>\n      <th>ET_30_16</th>\n      <td>0.523057</td>\n      <td>0.896837</td>\n      <td>0.826041</td>\n      <td>-0.078940</td>\n    </tr>\n    <tr>\n      <th>ET_30_20</th>\n      <td>0.626345</td>\n      <td>0.962922</td>\n      <td>0.856285</td>\n      <td>-0.110744</td>\n    </tr>\n    <tr>\n      <th>ET_50_4</th>\n      <td>0.405657</td>\n      <td>0.732375</td>\n      <td>0.709612</td>\n      <td>-0.031081</td>\n    </tr>\n    <tr>\n      <th>ET_50_8</th>\n      <td>0.565447</td>\n      <td>0.765167</td>\n      <td>0.734255</td>\n      <td>-0.040399</td>\n    </tr>\n    <tr>\n      <th>ET_50_12</th>\n      <td>0.716370</td>\n      <td>0.829453</td>\n      <td>0.784921</td>\n      <td>-0.053688</td>\n    </tr>\n    <tr>\n      <th>ET_50_16</th>\n      <td>0.883430</td>\n      <td>0.896631</td>\n      <td>0.818996</td>\n      <td>-0.086585</td>\n    </tr>\n    <tr>\n      <th>ET_50_20</th>\n      <td>1.063757</td>\n      <td>0.969024</td>\n      <td>0.862790</td>\n      <td>-0.109630</td>\n    </tr>\n    <tr>\n      <th>ET_100_4</th>\n      <td>0.795927</td>\n      <td>0.716622</td>\n      <td>0.693258</td>\n      <td>-0.032603</td>\n    </tr>\n    <tr>\n      <th>ET_100_8</th>\n      <td>1.087413</td>\n      <td>0.772581</td>\n      <td>0.742928</td>\n      <td>-0.038381</td>\n    </tr>\n    <tr>\n      <th>ET_100_12</th>\n      <td>1.433501</td>\n      <td>0.829148</td>\n      <td>0.782651</td>\n      <td>-0.056079</td>\n    </tr>\n    <tr>\n      <th>ET_100_16</th>\n      <td>1.727899</td>\n      <td>0.902929</td>\n      <td>0.827694</td>\n      <td>-0.083323</td>\n    </tr>\n    <tr>\n      <th>ET_100_20</th>\n      <td>2.039556</td>\n      <td>0.965089</td>\n      <td>0.861569</td>\n      <td>-0.107264</td>\n    </tr>\n    <tr>\n      <th>ET_250_4</th>\n      <td>1.863411</td>\n      <td>0.726130</td>\n      <td>0.706487</td>\n      <td>-0.027052</td>\n    </tr>\n    <tr>\n      <th>ET_250_8</th>\n      <td>2.659302</td>\n      <td>0.772875</td>\n      <td>0.745876</td>\n      <td>-0.034933</td>\n    </tr>\n    <tr>\n      <th>ET_250_12</th>\n      <td>3.466692</td>\n      <td>0.835571</td>\n      <td>0.789267</td>\n      <td>-0.055416</td>\n    </tr>\n    <tr>\n      <th>ET_250_16</th>\n      <td>4.430279</td>\n      <td>0.904650</td>\n      <td>0.830463</td>\n      <td>-0.082007</td>\n    </tr>\n    <tr>\n      <th>ET_250_20</th>\n      <td>5.558471</td>\n      <td>0.967856</td>\n      <td>0.863450</td>\n      <td>-0.107873</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"obviamente el overfitting está controlado pero en cuanto a precisión no es mejor que lo anterior","metadata":{"cell_id":"b509257e48464278a14ad194c63d8d59","formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"## boosting","metadata":{"cell_id":"e270f821aa6440d0961b5f8c853a7098","formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"### adaboost","metadata":{"cell_id":"f24da0b460cd4f6ba0514ed4bae429b5","formattedRanges":[],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"metrics = {}\nfor n_estimators in [3, 5, 10, 15, 30, 50, 100, 250]:\n    for eta in [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1]:\n        start_time = time.time()\n        model = AdaBoostClassifier(n_estimators = n_estimators, learning_rate = eta)\n        model.fit(X_train, y_train);\n        \n        train_pred = model.predict_proba(X_train)[:, 1]\n        test_pred = model.predict_proba(X_validation)[:, 1]\n\n        metrics['AdaB_'+ str(n_estimators)+'_'+str(eta)] = {\n            'Train_Gini': 2*roc_auc_score(y_train, train_pred)-1,\n            'Test_Gini': 2*roc_auc_score(y_validation, test_pred)-1,\n            'Run_Time': time.time() - start_time\n            }\n\nmetrics_AdaB = pd.DataFrame.from_dict(metrics, orient='index',columns=['Run_Time', 'Train_Gini', 'Test_Gini'])\nmetrics_AdaB['delta'] = (metrics_AdaB.Test_Gini - metrics_AdaB.Train_Gini) / metrics_AdaB.Train_Gini\nmetrics_AdaB","metadata":{"cell_id":"894b84931c5e4651b058908b5213b7c6","source_hash":"b8a5b8d0","execution_start":1684091566763,"execution_millis":57641,"deepnote_table_state":{"sortBy":[{"id":"delta","type":"asc"}],"filters":[],"pageSize":10,"pageIndex":5},"deepnote_table_loading":false,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n","output_type":"stream"},{"output_type":"execute_result","execution_count":8,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":4,"row_count":56,"columns":[{"name":"Run_Time","dtype":"float64","stats":{"unique_count":56,"nan_count":0,"min":"0.07230758666992188","max":"4.3792266845703125","histogram":[{"bin_start":0.07230758666992188,"bin_end":0.5029994964599609,"count":28},{"bin_start":0.5029994964599609,"bin_end":0.93369140625,"count":14},{"bin_start":0.93369140625,"bin_end":1.3643833160400392,"count":0},{"bin_start":1.3643833160400392,"bin_end":1.7950752258300782,"count":6},{"bin_start":1.7950752258300782,"bin_end":2.225767135620117,"count":1},{"bin_start":2.225767135620117,"bin_end":2.6564590454101564,"count":0},{"bin_start":2.6564590454101564,"bin_end":3.0871509552001952,"count":0},{"bin_start":3.0871509552001952,"bin_end":3.5178428649902345,"count":0},{"bin_start":3.5178428649902345,"bin_end":3.9485347747802737,"count":0},{"bin_start":3.9485347747802737,"bin_end":4.3792266845703125,"count":7}]}},{"name":"Train_Gini","dtype":"float64","stats":{"unique_count":33,"nan_count":0,"min":"0.3574818555345938","max":"0.7921702981057015","histogram":[{"bin_start":0.3574818555345938,"bin_end":0.40095069979170456,"count":20},{"bin_start":0.40095069979170456,"bin_end":0.44441954404881534,"count":6},{"bin_start":0.44441954404881534,"bin_end":0.48788838830592607,"count":0},{"bin_start":0.48788838830592607,"bin_end":0.5313572325630369,"count":0},{"bin_start":0.5313572325630369,"bin_end":0.5748260768201476,"count":4},{"bin_start":0.5748260768201476,"bin_end":0.6182949210772584,"count":3},{"bin_start":0.6182949210772584,"bin_end":0.6617637653343691,"count":2},{"bin_start":0.6617637653343691,"bin_end":0.7052326095914799,"count":4},{"bin_start":0.7052326095914799,"bin_end":0.7487014538485908,"count":8},{"bin_start":0.7487014538485908,"bin_end":0.7921702981057015,"count":9}]}},{"name":"Test_Gini","dtype":"float64","stats":{"unique_count":33,"nan_count":0,"min":"0.3342557801266599","max":"0.7653901234686691","histogram":[{"bin_start":0.3342557801266599,"bin_end":0.3773692144608608,"count":20},{"bin_start":0.3773692144608608,"bin_end":0.42048264879506175,"count":3},{"bin_start":0.42048264879506175,"bin_end":0.46359608312926265,"count":3},{"bin_start":0.46359608312926265,"bin_end":0.5067095174634636,"count":0},{"bin_start":0.5067095174634636,"bin_end":0.5498229517976645,"count":4},{"bin_start":0.5498229517976645,"bin_end":0.5929363861318654,"count":3},{"bin_start":0.5929363861318654,"bin_end":0.6360498204660663,"count":2},{"bin_start":0.6360498204660663,"bin_end":0.6791632548002673,"count":4},{"bin_start":0.6791632548002673,"bin_end":0.7222766891344681,"count":7},{"bin_start":0.7222766891344681,"bin_end":0.7653901234686691,"count":10}]}},{"name":"delta","dtype":"float64","stats":{"unique_count":33,"nan_count":0,"min":"-0.06497134063825587","max":"-0.01602359823189141","histogram":[{"bin_start":-0.06497134063825587,"bin_end":-0.06007656639761942,"count":21},{"bin_start":-0.06007656639761942,"bin_end":-0.055181792156982976,"count":0},{"bin_start":-0.055181792156982976,"bin_end":-0.05028701791634653,"count":0},{"bin_start":-0.05028701791634653,"bin_end":-0.045392243675710084,"count":2},{"bin_start":-0.045392243675710084,"bin_end":-0.04049746943507364,"count":7},{"bin_start":-0.04049746943507364,"bin_end":-0.03560269519443719,"count":5},{"bin_start":-0.03560269519443719,"bin_end":-0.030707920953800746,"count":10},{"bin_start":-0.030707920953800746,"bin_end":-0.0258131467131643,"count":7},{"bin_start":-0.0258131467131643,"bin_end":-0.020918372472527855,"count":0},{"bin_start":-0.020918372472527855,"bin_end":-0.01602359823189141,"count":4}]}},{"name":"_deepnote_index_column","dtype":"object"}],"rows":[{"Run_Time":"1.7636792659759521","Train_Gini":"0.7395449653586648","Test_Gini":"0.7183979382865133","delta":"-0.028594646793242036","_deepnote_index_column":"AdaB_100_0.1"},{"Run_Time":"0.29816412925720215","Train_Gini":"0.7254843185628017","Test_Gini":"0.7062672497710722","delta":"-0.02648860671420003","_deepnote_index_column":"AdaB_15_0.5"},{"Run_Time":"0.19573187828063965","Train_Gini":"0.7196397257498834","Test_Gini":"0.705362604019828","delta":"-0.019839262924483955","_deepnote_index_column":"AdaB_10_1"},{"Run_Time":"1.7413175106048584","Train_Gini":"0.44089325144091873","Test_Gini":"0.4338285551166772","delta":"-0.01602359823189141","_deepnote_index_column":"AdaB_100_0.005"},{"Run_Time":"0.21088218688964844","Train_Gini":"0.44089325144091873","Test_Gini":"0.4338285551166772","delta":"-0.01602359823189141","_deepnote_index_column":"AdaB_10_0.05"},{"Run_Time":"0.9011847972869873","Train_Gini":"0.44089325144091873","Test_Gini":"0.4338285551166772","delta":"-0.01602359823189141","_deepnote_index_column":"AdaB_50_0.01"}]},"text/plain":"                Run_Time  Train_Gini  Test_Gini     delta\nAdaB_3_0.001    0.090037    0.357482   0.334256 -0.064971\nAdaB_3_0.005    0.075628    0.357482   0.334256 -0.064971\nAdaB_3_0.01     0.072308    0.357482   0.334256 -0.064971\nAdaB_3_0.05     0.078245    0.357482   0.334256 -0.064971\nAdaB_3_0.1      0.075918    0.357482   0.334256 -0.064971\nAdaB_3_0.5      0.073300    0.561381   0.524921 -0.064948\nAdaB_3_1        0.079175    0.598295   0.573274 -0.041821\nAdaB_5_0.001    0.108146    0.357482   0.334256 -0.064971\nAdaB_5_0.005    0.104645    0.357482   0.334256 -0.064971\nAdaB_5_0.01     0.106986    0.357482   0.334256 -0.064971\nAdaB_5_0.05     0.106717    0.357482   0.334256 -0.064971\nAdaB_5_0.1      0.126525    0.431935   0.416019 -0.036850\nAdaB_5_0.5      0.120832    0.645696   0.617085 -0.044311\nAdaB_5_1        0.108842    0.673964   0.651863 -0.032793\nAdaB_10_0.001   0.198473    0.357482   0.334256 -0.064971\nAdaB_10_0.005   0.188752    0.357482   0.334256 -0.064971\nAdaB_10_0.01    0.196682    0.357482   0.334256 -0.064971\nAdaB_10_0.05    0.210882    0.440893   0.433829 -0.016024\nAdaB_10_0.1     0.195369    0.546268   0.518799 -0.050285\nAdaB_10_0.5     0.204182    0.705546   0.684282 -0.030138\nAdaB_10_1       0.195732    0.719640   0.705363 -0.019839\nAdaB_15_0.001   0.289249    0.357482   0.334256 -0.064971\nAdaB_15_0.005   0.297436    0.357482   0.334256 -0.064971\nAdaB_15_0.01    0.284928    0.357482   0.334256 -0.064971\nAdaB_15_0.05    0.274207    0.541653   0.515362 -0.048540\nAdaB_15_0.1     0.298376    0.623508   0.596074 -0.043999\nAdaB_15_0.5     0.298164    0.725484   0.706267 -0.026489\nAdaB_15_1       0.288601    0.737222   0.715122 -0.029977\nAdaB_30_0.001   0.548865    0.357482   0.334256 -0.064971\nAdaB_30_0.005   0.531312    0.357482   0.334256 -0.064971\nAdaB_30_0.01    0.545963    0.431935   0.416019 -0.036850\nAdaB_30_0.05    0.549681    0.612532   0.586025 -0.043274\nAdaB_30_0.1     0.561836    0.683193   0.656176 -0.039545\nAdaB_30_0.5     0.528103    0.750611   0.727856 -0.030315\nAdaB_30_1       0.558386    0.758414   0.733569 -0.032759\nAdaB_50_0.001   0.886266    0.357482   0.334256 -0.064971\nAdaB_50_0.005   0.880675    0.357482   0.334256 -0.064971\nAdaB_50_0.01    0.901185    0.440893   0.433829 -0.016024\nAdaB_50_0.05    0.889534    0.673358   0.645748 -0.041003\nAdaB_50_0.1     0.887641    0.710245   0.687402 -0.032161\nAdaB_50_0.5     0.884250    0.763520   0.740677 -0.029918\nAdaB_50_1       0.906059    0.770368   0.745873 -0.031796\nAdaB_100_0.001  1.801123    0.357482   0.334256 -0.064971\nAdaB_100_0.005  1.741318    0.440893   0.433829 -0.016024\nAdaB_100_0.01   1.756470    0.560415   0.538750 -0.038659\nAdaB_100_0.05   1.743898    0.709201   0.685185 -0.033864\nAdaB_100_0.1    1.763679    0.739545   0.718398 -0.028595\nAdaB_100_0.5    1.735686    0.771664   0.747480 -0.031340\nAdaB_100_1      1.785539    0.780683   0.755347 -0.032454\nAdaB_250_0.001  4.291739    0.431935   0.416019 -0.036850\nAdaB_250_0.005  4.370254    0.576139   0.550514 -0.044476\nAdaB_250_0.01   4.368738    0.670217   0.642973 -0.040649\nAdaB_250_0.05   4.379227    0.744909   0.722349 -0.030285\nAdaB_250_0.1    4.324363    0.762207   0.737584 -0.032305\nAdaB_250_0.5    4.378926    0.782700   0.758039 -0.031508\nAdaB_250_1      4.363487    0.792170   0.765390 -0.033806","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Run_Time</th>\n      <th>Train_Gini</th>\n      <th>Test_Gini</th>\n      <th>delta</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AdaB_3_0.001</th>\n      <td>0.090037</td>\n      <td>0.357482</td>\n      <td>0.334256</td>\n      <td>-0.064971</td>\n    </tr>\n    <tr>\n      <th>AdaB_3_0.005</th>\n      <td>0.075628</td>\n      <td>0.357482</td>\n      <td>0.334256</td>\n      <td>-0.064971</td>\n    </tr>\n    <tr>\n      <th>AdaB_3_0.01</th>\n      <td>0.072308</td>\n      <td>0.357482</td>\n      <td>0.334256</td>\n      <td>-0.064971</td>\n    </tr>\n    <tr>\n      <th>AdaB_3_0.05</th>\n      <td>0.078245</td>\n      <td>0.357482</td>\n      <td>0.334256</td>\n      <td>-0.064971</td>\n    </tr>\n    <tr>\n      <th>AdaB_3_0.1</th>\n      <td>0.075918</td>\n      <td>0.357482</td>\n      <td>0.334256</td>\n      <td>-0.064971</td>\n    </tr>\n    <tr>\n      <th>AdaB_3_0.5</th>\n      <td>0.073300</td>\n      <td>0.561381</td>\n      <td>0.524921</td>\n      <td>-0.064948</td>\n    </tr>\n    <tr>\n      <th>AdaB_3_1</th>\n      <td>0.079175</td>\n      <td>0.598295</td>\n      <td>0.573274</td>\n      <td>-0.041821</td>\n    </tr>\n    <tr>\n      <th>AdaB_5_0.001</th>\n      <td>0.108146</td>\n      <td>0.357482</td>\n      <td>0.334256</td>\n      <td>-0.064971</td>\n    </tr>\n    <tr>\n      <th>AdaB_5_0.005</th>\n      <td>0.104645</td>\n      <td>0.357482</td>\n      <td>0.334256</td>\n      <td>-0.064971</td>\n    </tr>\n    <tr>\n      <th>AdaB_5_0.01</th>\n      <td>0.106986</td>\n      <td>0.357482</td>\n      <td>0.334256</td>\n      <td>-0.064971</td>\n    </tr>\n    <tr>\n      <th>AdaB_5_0.05</th>\n      <td>0.106717</td>\n      <td>0.357482</td>\n      <td>0.334256</td>\n      <td>-0.064971</td>\n    </tr>\n    <tr>\n      <th>AdaB_5_0.1</th>\n      <td>0.126525</td>\n      <td>0.431935</td>\n      <td>0.416019</td>\n      <td>-0.036850</td>\n    </tr>\n    <tr>\n      <th>AdaB_5_0.5</th>\n      <td>0.120832</td>\n      <td>0.645696</td>\n      <td>0.617085</td>\n      <td>-0.044311</td>\n    </tr>\n    <tr>\n      <th>AdaB_5_1</th>\n      <td>0.108842</td>\n      <td>0.673964</td>\n      <td>0.651863</td>\n      <td>-0.032793</td>\n    </tr>\n    <tr>\n      <th>AdaB_10_0.001</th>\n      <td>0.198473</td>\n      <td>0.357482</td>\n      <td>0.334256</td>\n      <td>-0.064971</td>\n    </tr>\n    <tr>\n      <th>AdaB_10_0.005</th>\n      <td>0.188752</td>\n      <td>0.357482</td>\n      <td>0.334256</td>\n      <td>-0.064971</td>\n    </tr>\n    <tr>\n      <th>AdaB_10_0.01</th>\n      <td>0.196682</td>\n      <td>0.357482</td>\n      <td>0.334256</td>\n      <td>-0.064971</td>\n    </tr>\n    <tr>\n      <th>AdaB_10_0.05</th>\n      <td>0.210882</td>\n      <td>0.440893</td>\n      <td>0.433829</td>\n      <td>-0.016024</td>\n    </tr>\n    <tr>\n      <th>AdaB_10_0.1</th>\n      <td>0.195369</td>\n      <td>0.546268</td>\n      <td>0.518799</td>\n      <td>-0.050285</td>\n    </tr>\n    <tr>\n      <th>AdaB_10_0.5</th>\n      <td>0.204182</td>\n      <td>0.705546</td>\n      <td>0.684282</td>\n      <td>-0.030138</td>\n    </tr>\n    <tr>\n      <th>AdaB_10_1</th>\n      <td>0.195732</td>\n      <td>0.719640</td>\n      <td>0.705363</td>\n      <td>-0.019839</td>\n    </tr>\n    <tr>\n      <th>AdaB_15_0.001</th>\n      <td>0.289249</td>\n      <td>0.357482</td>\n      <td>0.334256</td>\n      <td>-0.064971</td>\n    </tr>\n    <tr>\n      <th>AdaB_15_0.005</th>\n      <td>0.297436</td>\n      <td>0.357482</td>\n      <td>0.334256</td>\n      <td>-0.064971</td>\n    </tr>\n    <tr>\n      <th>AdaB_15_0.01</th>\n      <td>0.284928</td>\n      <td>0.357482</td>\n      <td>0.334256</td>\n      <td>-0.064971</td>\n    </tr>\n    <tr>\n      <th>AdaB_15_0.05</th>\n      <td>0.274207</td>\n      <td>0.541653</td>\n      <td>0.515362</td>\n      <td>-0.048540</td>\n    </tr>\n    <tr>\n      <th>AdaB_15_0.1</th>\n      <td>0.298376</td>\n      <td>0.623508</td>\n      <td>0.596074</td>\n      <td>-0.043999</td>\n    </tr>\n    <tr>\n      <th>AdaB_15_0.5</th>\n      <td>0.298164</td>\n      <td>0.725484</td>\n      <td>0.706267</td>\n      <td>-0.026489</td>\n    </tr>\n    <tr>\n      <th>AdaB_15_1</th>\n      <td>0.288601</td>\n      <td>0.737222</td>\n      <td>0.715122</td>\n      <td>-0.029977</td>\n    </tr>\n    <tr>\n      <th>AdaB_30_0.001</th>\n      <td>0.548865</td>\n      <td>0.357482</td>\n      <td>0.334256</td>\n      <td>-0.064971</td>\n    </tr>\n    <tr>\n      <th>AdaB_30_0.005</th>\n      <td>0.531312</td>\n      <td>0.357482</td>\n      <td>0.334256</td>\n      <td>-0.064971</td>\n    </tr>\n    <tr>\n      <th>AdaB_30_0.01</th>\n      <td>0.545963</td>\n      <td>0.431935</td>\n      <td>0.416019</td>\n      <td>-0.036850</td>\n    </tr>\n    <tr>\n      <th>AdaB_30_0.05</th>\n      <td>0.549681</td>\n      <td>0.612532</td>\n      <td>0.586025</td>\n      <td>-0.043274</td>\n    </tr>\n    <tr>\n      <th>AdaB_30_0.1</th>\n      <td>0.561836</td>\n      <td>0.683193</td>\n      <td>0.656176</td>\n      <td>-0.039545</td>\n    </tr>\n    <tr>\n      <th>AdaB_30_0.5</th>\n      <td>0.528103</td>\n      <td>0.750611</td>\n      <td>0.727856</td>\n      <td>-0.030315</td>\n    </tr>\n    <tr>\n      <th>AdaB_30_1</th>\n      <td>0.558386</td>\n      <td>0.758414</td>\n      <td>0.733569</td>\n      <td>-0.032759</td>\n    </tr>\n    <tr>\n      <th>AdaB_50_0.001</th>\n      <td>0.886266</td>\n      <td>0.357482</td>\n      <td>0.334256</td>\n      <td>-0.064971</td>\n    </tr>\n    <tr>\n      <th>AdaB_50_0.005</th>\n      <td>0.880675</td>\n      <td>0.357482</td>\n      <td>0.334256</td>\n      <td>-0.064971</td>\n    </tr>\n    <tr>\n      <th>AdaB_50_0.01</th>\n      <td>0.901185</td>\n      <td>0.440893</td>\n      <td>0.433829</td>\n      <td>-0.016024</td>\n    </tr>\n    <tr>\n      <th>AdaB_50_0.05</th>\n      <td>0.889534</td>\n      <td>0.673358</td>\n      <td>0.645748</td>\n      <td>-0.041003</td>\n    </tr>\n    <tr>\n      <th>AdaB_50_0.1</th>\n      <td>0.887641</td>\n      <td>0.710245</td>\n      <td>0.687402</td>\n      <td>-0.032161</td>\n    </tr>\n    <tr>\n      <th>AdaB_50_0.5</th>\n      <td>0.884250</td>\n      <td>0.763520</td>\n      <td>0.740677</td>\n      <td>-0.029918</td>\n    </tr>\n    <tr>\n      <th>AdaB_50_1</th>\n      <td>0.906059</td>\n      <td>0.770368</td>\n      <td>0.745873</td>\n      <td>-0.031796</td>\n    </tr>\n    <tr>\n      <th>AdaB_100_0.001</th>\n      <td>1.801123</td>\n      <td>0.357482</td>\n      <td>0.334256</td>\n      <td>-0.064971</td>\n    </tr>\n    <tr>\n      <th>AdaB_100_0.005</th>\n      <td>1.741318</td>\n      <td>0.440893</td>\n      <td>0.433829</td>\n      <td>-0.016024</td>\n    </tr>\n    <tr>\n      <th>AdaB_100_0.01</th>\n      <td>1.756470</td>\n      <td>0.560415</td>\n      <td>0.538750</td>\n      <td>-0.038659</td>\n    </tr>\n    <tr>\n      <th>AdaB_100_0.05</th>\n      <td>1.743898</td>\n      <td>0.709201</td>\n      <td>0.685185</td>\n      <td>-0.033864</td>\n    </tr>\n    <tr>\n      <th>AdaB_100_0.1</th>\n      <td>1.763679</td>\n      <td>0.739545</td>\n      <td>0.718398</td>\n      <td>-0.028595</td>\n    </tr>\n    <tr>\n      <th>AdaB_100_0.5</th>\n      <td>1.735686</td>\n      <td>0.771664</td>\n      <td>0.747480</td>\n      <td>-0.031340</td>\n    </tr>\n    <tr>\n      <th>AdaB_100_1</th>\n      <td>1.785539</td>\n      <td>0.780683</td>\n      <td>0.755347</td>\n      <td>-0.032454</td>\n    </tr>\n    <tr>\n      <th>AdaB_250_0.001</th>\n      <td>4.291739</td>\n      <td>0.431935</td>\n      <td>0.416019</td>\n      <td>-0.036850</td>\n    </tr>\n    <tr>\n      <th>AdaB_250_0.005</th>\n      <td>4.370254</td>\n      <td>0.576139</td>\n      <td>0.550514</td>\n      <td>-0.044476</td>\n    </tr>\n    <tr>\n      <th>AdaB_250_0.01</th>\n      <td>4.368738</td>\n      <td>0.670217</td>\n      <td>0.642973</td>\n      <td>-0.040649</td>\n    </tr>\n    <tr>\n      <th>AdaB_250_0.05</th>\n      <td>4.379227</td>\n      <td>0.744909</td>\n      <td>0.722349</td>\n      <td>-0.030285</td>\n    </tr>\n    <tr>\n      <th>AdaB_250_0.1</th>\n      <td>4.324363</td>\n      <td>0.762207</td>\n      <td>0.737584</td>\n      <td>-0.032305</td>\n    </tr>\n    <tr>\n      <th>AdaB_250_0.5</th>\n      <td>4.378926</td>\n      <td>0.782700</td>\n      <td>0.758039</td>\n      <td>-0.031508</td>\n    </tr>\n    <tr>\n      <th>AdaB_250_1</th>\n      <td>4.363487</td>\n      <td>0.792170</td>\n      <td>0.765390</td>\n      <td>-0.033806</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"malillos","metadata":{"cell_id":"b6e4d60006014499995b5f4c8d4e0ae1","formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"### xgb","metadata":{"cell_id":"02f7724bb22c43749770b57c1bcf9c76","formattedRanges":[],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"metrics = {}\nfor n_estimators in [3, 5, 10, 15, 30, 50, 100, 250]:\n    for max_depth in [4, 8, 12, 16, 20]:\n        for eta in [0.01, 0.05, 0.1]:\n            start_time = time.time()\n            model = XGBClassifier(max_depth=max_depth, eta=eta, n_estimators=n_estimators)\n            model.fit(X_train, y_train);\n            \n            train_pred = model.predict_proba(X_train)[:, 1]\n            test_pred = model.predict_proba(X_validation)[:, 1]\n\n            metrics['XGB_'+ str(n_estimators)+'_'+str(max_depth)] = {\n                'Learning_Rate': eta,\n                'Train_Gini': 2*roc_auc_score(y_train, train_pred)-1,\n                'Test_Gini': 2*roc_auc_score(y_validation, test_pred)-1,\n                'Run_Time': time.time() - start_time\n                }\n\nmetrics_XGB = pd.DataFrame.from_dict(metrics, orient='index',columns=['Learning_Rate', 'Run_Time', 'Train_Gini', 'Test_Gini'])\nmetrics_XGB['delta'] = (metrics_XGB.Test_Gini - metrics_XGB.Train_Gini) / metrics_XGB.Train_Gini\nmetrics_XGB","metadata":{"cell_id":"01681c65162c4772ac2f6c2858e5fe11","source_hash":"3aac8914","execution_start":1684094011829,"execution_millis":494616,"deepnote_table_state":{"sortBy":[{"id":"delta","type":"asc"}],"filters":[],"pageSize":10,"pageIndex":2},"deepnote_table_loading":false,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":7,"row_count":40,"columns":[{"name":"Learning_Rate","dtype":"float64","stats":{"unique_count":1,"nan_count":0,"min":"0.1","max":"0.1","histogram":[{"bin_start":-0.4,"bin_end":-0.30000000000000004,"count":0},{"bin_start":-0.30000000000000004,"bin_end":-0.2,"count":0},{"bin_start":-0.2,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.09999999999999998,"count":0},{"bin_start":0.09999999999999998,"bin_end":0.20000000000000007,"count":40},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6,"count":0}]}},{"name":"Lambda","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"1","max":"1","histogram":[{"bin_start":0.5,"bin_end":0.6,"count":0},{"bin_start":0.6,"bin_end":0.7,"count":0},{"bin_start":0.7,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":0},{"bin_start":1,"bin_end":1.1,"count":40},{"bin_start":1.1,"bin_end":1.2000000000000002,"count":0},{"bin_start":1.2000000000000002,"bin_end":1.3,"count":0},{"bin_start":1.3,"bin_end":1.4,"count":0},{"bin_start":1.4,"bin_end":1.5,"count":0}]}},{"name":"Gamma","dtype":"int64","stats":{"unique_count":1,"nan_count":0,"min":"1","max":"1","histogram":[{"bin_start":0.5,"bin_end":0.6,"count":0},{"bin_start":0.6,"bin_end":0.7,"count":0},{"bin_start":0.7,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":0},{"bin_start":1,"bin_end":1.1,"count":40},{"bin_start":1.1,"bin_end":1.2000000000000002,"count":0},{"bin_start":1.2000000000000002,"bin_end":1.3,"count":0},{"bin_start":1.3,"bin_end":1.4,"count":0},{"bin_start":1.4,"bin_end":1.5,"count":0}]}},{"name":"Run_Time","dtype":"float64","stats":{"unique_count":40,"nan_count":0,"min":"0.12091660499572754","max":"28.84690809249878","histogram":[{"bin_start":0.12091660499572754,"bin_end":2.9935157537460326,"count":26},{"bin_start":2.9935157537460326,"bin_end":5.866114902496338,"count":6},{"bin_start":5.866114902496338,"bin_end":8.738714051246642,"count":2},{"bin_start":8.738714051246642,"bin_end":11.611313199996948,"count":2},{"bin_start":11.611313199996948,"bin_end":14.483912348747253,"count":1},{"bin_start":14.483912348747253,"bin_end":17.356511497497557,"count":1},{"bin_start":17.356511497497557,"bin_end":20.229110646247864,"count":0},{"bin_start":20.229110646247864,"bin_end":23.10170979499817,"count":1},{"bin_start":23.10170979499817,"bin_end":25.974308943748472,"count":0},{"bin_start":25.974308943748472,"bin_end":28.84690809249878,"count":1}]}},{"name":"Train_Gini","dtype":"float64","stats":{"unique_count":40,"nan_count":0,"min":"0.7532071340528199","max":"0.9993496616245876","histogram":[{"bin_start":0.7532071340528199,"bin_end":0.7778213868099967,"count":3},{"bin_start":0.7778213868099967,"bin_end":0.8024356395671735,"count":1},{"bin_start":0.8024356395671735,"bin_end":0.8270498923243502,"count":1},{"bin_start":0.8270498923243502,"bin_end":0.851664145081527,"count":1},{"bin_start":0.851664145081527,"bin_end":0.8762783978387038,"count":3},{"bin_start":0.8762783978387038,"bin_end":0.9008926505958805,"count":3},{"bin_start":0.9008926505958805,"bin_end":0.9255069033530573,"count":4},{"bin_start":0.9255069033530573,"bin_end":0.9501211561102341,"count":7},{"bin_start":0.9501211561102341,"bin_end":0.9747354088674108,"count":7},{"bin_start":0.9747354088674108,"bin_end":0.9993496616245876,"count":10}]}},{"name":"Test_Gini","dtype":"float64","stats":{"unique_count":40,"nan_count":0,"min":"0.7259651452388629","max":"0.8955853415635087","histogram":[{"bin_start":0.7259651452388629,"bin_end":0.7429271648713275,"count":2},{"bin_start":0.7429271648713275,"bin_end":0.7598891845037921,"count":1},{"bin_start":0.7598891845037921,"bin_end":0.7768512041362566,"count":1},{"bin_start":0.7768512041362566,"bin_end":0.7938132237687212,"count":0},{"bin_start":0.7938132237687212,"bin_end":0.8107752434011858,"count":1},{"bin_start":0.8107752434011858,"bin_end":0.8277372630336504,"count":2},{"bin_start":0.8277372630336504,"bin_end":0.8446992826661149,"count":2},{"bin_start":0.8446992826661149,"bin_end":0.8616613022985795,"count":5},{"bin_start":0.8616613022985795,"bin_end":0.8786233219310441,"count":10},{"bin_start":0.8786233219310441,"bin_end":0.8955853415635087,"count":16}]}},{"name":"delta","dtype":"float64","stats":{"unique_count":40,"nan_count":0,"min":"-0.10678729759669212","max":"-0.03223605569224766","histogram":[{"bin_start":-0.10678729759669212,"bin_end":-0.09933217340624767,"count":6},{"bin_start":-0.09933217340624767,"bin_end":-0.09187704921580322,"count":4},{"bin_start":-0.09187704921580322,"bin_end":-0.08442192502535878,"count":6},{"bin_start":-0.08442192502535878,"bin_end":-0.07696680083491433,"count":3},{"bin_start":-0.07696680083491433,"bin_end":-0.06951167664446989,"count":2},{"bin_start":-0.06951167664446989,"bin_end":-0.06205655245402544,"count":4},{"bin_start":-0.06205655245402544,"bin_end":-0.054601428263581,"count":1},{"bin_start":-0.054601428263581,"bin_end":-0.04714630407313655,"count":1},{"bin_start":-0.04714630407313655,"bin_end":-0.03969117988269211,"count":6},{"bin_start":-0.03969117988269211,"bin_end":-0.03223605569224766,"count":7}]}},{"name":"_deepnote_index_column","dtype":"object"}],"rows":[{"Learning_Rate":"0.1","Lambda":"1","Gamma":"1","Run_Time":"2.3837671279907227","Train_Gini":"0.9489430619310477","Test_Gini":"0.8815597240998847","delta":"-0.07100883133498186","_deepnote_index_column":"XGB_30_12"},{"Learning_Rate":"0.1","Lambda":"1","Gamma":"1","Run_Time":"1.2230122089385986","Train_Gini":"0.9369981825528713","Test_Gini":"0.87345704255732","delta":"-0.06781351466705308","_deepnote_index_column":"XGB_15_12"},{"Learning_Rate":"0.1","Lambda":"1","Gamma":"1","Run_Time":"0.5257186889648438","Train_Gini":"0.9205786661458373","Test_Gini":"0.8591865404877486","delta":"-0.06668862522647578","_deepnote_index_column":"XGB_5_12"},{"Learning_Rate":"0.1","Lambda":"1","Gamma":"1","Run_Time":"0.822333574295044","Train_Gini":"0.9309587442775149","Test_Gini":"0.8693820472481353","delta":"-0.06614331452159804","_deepnote_index_column":"XGB_10_12"},{"Learning_Rate":"0.1","Lambda":"1","Gamma":"1","Run_Time":"0.2862112522125244","Train_Gini":"0.9137330116702873","Test_Gini":"0.8556762070630048","delta":"-0.06353803995891062","_deepnote_index_column":"XGB_3_12"},{"Learning_Rate":"0.1","Lambda":"1","Gamma":"1","Run_Time":"3.926729917526245","Train_Gini":"0.9363012823240628","Test_Gini":"0.8802785301791813","delta":"-0.059834108104416216","_deepnote_index_column":"XGB_100_8"},{"Learning_Rate":"0.1","Lambda":"1","Gamma":"1","Run_Time":"2.103571891784668","Train_Gini":"0.917084664957968","Test_Gini":"0.8731916306235656","delta":"-0.047861485434841616","_deepnote_index_column":"XGB_50_8"},{"Learning_Rate":"0.1","Lambda":"1","Gamma":"1","Run_Time":"4.5267109870910645","Train_Gini":"0.8993463518849694","Test_Gini":"0.8575177328849393","delta":"-0.046510022431691785","_deepnote_index_column":"XGB_250_4"},{"Learning_Rate":"0.1","Lambda":"1","Gamma":"1","Run_Time":"0.19509506225585938","Train_Gini":"0.8613024589183116","Test_Gini":"0.8219955128544374","delta":"-0.045636635141200935","_deepnote_index_column":"XGB_3_8"},{"Learning_Rate":"0.1","Lambda":"1","Gamma":"1","Run_Time":"1.3611319065093994","Train_Gini":"0.9074934105266448","Test_Gini":"0.8675143811571961","delta":"-0.04405434673762275","_deepnote_index_column":"XGB_30_8"}]},"text/plain":"            Learning_Rate  Lambda  Gamma   Run_Time  Train_Gini  Test_Gini  \\\nXGB_3_4               0.1       1      1   0.120917    0.753207   0.725965   \nXGB_3_8               0.1       1      1   0.195095    0.861302   0.821996   \nXGB_3_12              0.1       1      1   0.286211    0.913733   0.855676   \nXGB_3_16              0.1       1      1   0.357794    0.938817   0.862683   \nXGB_3_20              0.1       1      1   0.427415    0.948418   0.862609   \nXGB_5_4               0.1       1      1   0.152456    0.757413   0.729685   \nXGB_5_8               0.1       1      1   0.275965    0.869921   0.832022   \nXGB_5_12              0.1       1      1   0.525719    0.920579   0.859187   \nXGB_5_16              0.1       1      1   0.562686    0.945878   0.865688   \nXGB_5_20              0.1       1      1   0.649739    0.955829   0.866480   \nXGB_10_4              0.1       1      1   0.246338    0.777619   0.752021   \nXGB_10_8              0.1       1      1   0.491176    0.881062   0.844735   \nXGB_10_12             0.1       1      1   0.822334    0.930959   0.869382   \nXGB_10_16             0.1       1      1   1.117189    0.957341   0.875269   \nXGB_10_20             0.1       1      1   1.447767    0.968548   0.876311   \nXGB_15_4              0.1       1      1   0.330997    0.792656   0.766380   \nXGB_15_8              0.1       1      1   0.716858    0.888130   0.849780   \nXGB_15_12             0.1       1      1   1.223012    0.936998   0.873457   \nXGB_15_16             0.1       1      1   1.647889    0.964909   0.879366   \nXGB_15_20             0.1       1      1   1.927396    0.976264   0.880144   \nXGB_30_4              0.1       1      1   0.608439    0.825447   0.798838   \nXGB_30_8              0.1       1      1   1.361132    0.907493   0.867514   \nXGB_30_12             0.1       1      1   2.383767    0.948943   0.881560   \nXGB_30_16             0.1       1      1   3.223851    0.976354   0.886734   \nXGB_30_20             0.1       1      1   3.828907    0.987760   0.886985   \nXGB_50_4              0.1       1      1   0.958381    0.842452   0.813631   \nXGB_50_8              0.1       1      1   2.103572    0.917085   0.873192   \nXGB_50_12             0.1       1      1   3.585907    0.955696   0.887191   \nXGB_50_16             0.1       1      1   5.093747    0.981273   0.892725   \nXGB_50_20             0.1       1      1   6.377879    0.991955   0.893173   \nXGB_100_4             0.1       1      1   2.016614    0.864552   0.830711   \nXGB_100_8             0.1       1      1   3.926730    0.936301   0.880279   \nXGB_100_12            0.1       1      1   6.620967    0.974012   0.891871   \nXGB_100_16            0.1       1      1   9.291859    0.991836   0.895469   \nXGB_100_20            0.1       1      1  11.827589    0.996782   0.895585   \nXGB_250_4             0.1       1      1   4.526711    0.899346   0.857518   \nXGB_250_8             0.1       1      1   9.440149    0.970516   0.888816   \nXGB_250_12            0.1       1      1  15.588087    0.994889   0.893186   \nXGB_250_16            0.1       1      1  22.208350    0.998721   0.893774   \nXGB_250_20            0.1       1      1  28.846908    0.999350   0.892632   \n\n               delta  \nXGB_3_4    -0.036168  \nXGB_3_8    -0.045637  \nXGB_3_12   -0.063538  \nXGB_3_16   -0.081096  \nXGB_3_20   -0.090476  \nXGB_5_4    -0.036609  \nXGB_5_8    -0.043567  \nXGB_5_12   -0.066689  \nXGB_5_16   -0.084778  \nXGB_5_20   -0.093478  \nXGB_10_4   -0.032918  \nXGB_10_8   -0.041231  \nXGB_10_12  -0.066143  \nXGB_10_16  -0.085729  \nXGB_10_20  -0.095232  \nXGB_15_4   -0.033149  \nXGB_15_8   -0.043181  \nXGB_15_12  -0.067814  \nXGB_15_16  -0.088654  \nXGB_15_20  -0.098457  \nXGB_30_4   -0.032236  \nXGB_30_8   -0.044054  \nXGB_30_12  -0.071009  \nXGB_30_16  -0.091791  \nXGB_30_20  -0.102024  \nXGB_50_4   -0.034211  \nXGB_50_8   -0.047861  \nXGB_50_12  -0.071681  \nXGB_50_16  -0.090238  \nXGB_50_20  -0.099584  \nXGB_100_4  -0.039142  \nXGB_100_8  -0.059834  \nXGB_100_12 -0.084332  \nXGB_100_16 -0.097160  \nXGB_100_20 -0.101523  \nXGB_250_4  -0.046510  \nXGB_250_8  -0.084181  \nXGB_250_12 -0.102225  \nXGB_250_16 -0.105082  \nXGB_250_20 -0.106787  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Learning_Rate</th>\n      <th>Lambda</th>\n      <th>Gamma</th>\n      <th>Run_Time</th>\n      <th>Train_Gini</th>\n      <th>Test_Gini</th>\n      <th>delta</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>XGB_3_4</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.120917</td>\n      <td>0.753207</td>\n      <td>0.725965</td>\n      <td>-0.036168</td>\n    </tr>\n    <tr>\n      <th>XGB_3_8</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.195095</td>\n      <td>0.861302</td>\n      <td>0.821996</td>\n      <td>-0.045637</td>\n    </tr>\n    <tr>\n      <th>XGB_3_12</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.286211</td>\n      <td>0.913733</td>\n      <td>0.855676</td>\n      <td>-0.063538</td>\n    </tr>\n    <tr>\n      <th>XGB_3_16</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.357794</td>\n      <td>0.938817</td>\n      <td>0.862683</td>\n      <td>-0.081096</td>\n    </tr>\n    <tr>\n      <th>XGB_3_20</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.427415</td>\n      <td>0.948418</td>\n      <td>0.862609</td>\n      <td>-0.090476</td>\n    </tr>\n    <tr>\n      <th>XGB_5_4</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.152456</td>\n      <td>0.757413</td>\n      <td>0.729685</td>\n      <td>-0.036609</td>\n    </tr>\n    <tr>\n      <th>XGB_5_8</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.275965</td>\n      <td>0.869921</td>\n      <td>0.832022</td>\n      <td>-0.043567</td>\n    </tr>\n    <tr>\n      <th>XGB_5_12</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.525719</td>\n      <td>0.920579</td>\n      <td>0.859187</td>\n      <td>-0.066689</td>\n    </tr>\n    <tr>\n      <th>XGB_5_16</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.562686</td>\n      <td>0.945878</td>\n      <td>0.865688</td>\n      <td>-0.084778</td>\n    </tr>\n    <tr>\n      <th>XGB_5_20</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.649739</td>\n      <td>0.955829</td>\n      <td>0.866480</td>\n      <td>-0.093478</td>\n    </tr>\n    <tr>\n      <th>XGB_10_4</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.246338</td>\n      <td>0.777619</td>\n      <td>0.752021</td>\n      <td>-0.032918</td>\n    </tr>\n    <tr>\n      <th>XGB_10_8</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.491176</td>\n      <td>0.881062</td>\n      <td>0.844735</td>\n      <td>-0.041231</td>\n    </tr>\n    <tr>\n      <th>XGB_10_12</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.822334</td>\n      <td>0.930959</td>\n      <td>0.869382</td>\n      <td>-0.066143</td>\n    </tr>\n    <tr>\n      <th>XGB_10_16</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.117189</td>\n      <td>0.957341</td>\n      <td>0.875269</td>\n      <td>-0.085729</td>\n    </tr>\n    <tr>\n      <th>XGB_10_20</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.447767</td>\n      <td>0.968548</td>\n      <td>0.876311</td>\n      <td>-0.095232</td>\n    </tr>\n    <tr>\n      <th>XGB_15_4</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.330997</td>\n      <td>0.792656</td>\n      <td>0.766380</td>\n      <td>-0.033149</td>\n    </tr>\n    <tr>\n      <th>XGB_15_8</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.716858</td>\n      <td>0.888130</td>\n      <td>0.849780</td>\n      <td>-0.043181</td>\n    </tr>\n    <tr>\n      <th>XGB_15_12</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.223012</td>\n      <td>0.936998</td>\n      <td>0.873457</td>\n      <td>-0.067814</td>\n    </tr>\n    <tr>\n      <th>XGB_15_16</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.647889</td>\n      <td>0.964909</td>\n      <td>0.879366</td>\n      <td>-0.088654</td>\n    </tr>\n    <tr>\n      <th>XGB_15_20</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.927396</td>\n      <td>0.976264</td>\n      <td>0.880144</td>\n      <td>-0.098457</td>\n    </tr>\n    <tr>\n      <th>XGB_30_4</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.608439</td>\n      <td>0.825447</td>\n      <td>0.798838</td>\n      <td>-0.032236</td>\n    </tr>\n    <tr>\n      <th>XGB_30_8</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.361132</td>\n      <td>0.907493</td>\n      <td>0.867514</td>\n      <td>-0.044054</td>\n    </tr>\n    <tr>\n      <th>XGB_30_12</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.383767</td>\n      <td>0.948943</td>\n      <td>0.881560</td>\n      <td>-0.071009</td>\n    </tr>\n    <tr>\n      <th>XGB_30_16</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3.223851</td>\n      <td>0.976354</td>\n      <td>0.886734</td>\n      <td>-0.091791</td>\n    </tr>\n    <tr>\n      <th>XGB_30_20</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3.828907</td>\n      <td>0.987760</td>\n      <td>0.886985</td>\n      <td>-0.102024</td>\n    </tr>\n    <tr>\n      <th>XGB_50_4</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.958381</td>\n      <td>0.842452</td>\n      <td>0.813631</td>\n      <td>-0.034211</td>\n    </tr>\n    <tr>\n      <th>XGB_50_8</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.103572</td>\n      <td>0.917085</td>\n      <td>0.873192</td>\n      <td>-0.047861</td>\n    </tr>\n    <tr>\n      <th>XGB_50_12</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3.585907</td>\n      <td>0.955696</td>\n      <td>0.887191</td>\n      <td>-0.071681</td>\n    </tr>\n    <tr>\n      <th>XGB_50_16</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5.093747</td>\n      <td>0.981273</td>\n      <td>0.892725</td>\n      <td>-0.090238</td>\n    </tr>\n    <tr>\n      <th>XGB_50_20</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6.377879</td>\n      <td>0.991955</td>\n      <td>0.893173</td>\n      <td>-0.099584</td>\n    </tr>\n    <tr>\n      <th>XGB_100_4</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.016614</td>\n      <td>0.864552</td>\n      <td>0.830711</td>\n      <td>-0.039142</td>\n    </tr>\n    <tr>\n      <th>XGB_100_8</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3.926730</td>\n      <td>0.936301</td>\n      <td>0.880279</td>\n      <td>-0.059834</td>\n    </tr>\n    <tr>\n      <th>XGB_100_12</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6.620967</td>\n      <td>0.974012</td>\n      <td>0.891871</td>\n      <td>-0.084332</td>\n    </tr>\n    <tr>\n      <th>XGB_100_16</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9.291859</td>\n      <td>0.991836</td>\n      <td>0.895469</td>\n      <td>-0.097160</td>\n    </tr>\n    <tr>\n      <th>XGB_100_20</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>11.827589</td>\n      <td>0.996782</td>\n      <td>0.895585</td>\n      <td>-0.101523</td>\n    </tr>\n    <tr>\n      <th>XGB_250_4</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4.526711</td>\n      <td>0.899346</td>\n      <td>0.857518</td>\n      <td>-0.046510</td>\n    </tr>\n    <tr>\n      <th>XGB_250_8</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9.440149</td>\n      <td>0.970516</td>\n      <td>0.888816</td>\n      <td>-0.084181</td>\n    </tr>\n    <tr>\n      <th>XGB_250_12</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>15.588087</td>\n      <td>0.994889</td>\n      <td>0.893186</td>\n      <td>-0.102225</td>\n    </tr>\n    <tr>\n      <th>XGB_250_16</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>22.208350</td>\n      <td>0.998721</td>\n      <td>0.893774</td>\n      <td>-0.105082</td>\n    </tr>\n    <tr>\n      <th>XGB_250_20</th>\n      <td>0.1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>28.846908</td>\n      <td>0.999350</td>\n      <td>0.892632</td>\n      <td>-0.106787</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"quito lambda y gamma porque tarda mucho, se quedan por defecto","metadata":{"cell_id":"b6abf550f7464c98b2a35fe5ad88e91d","formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"aqui ya hay modelos bien finos","metadata":{"cell_id":"ac88dc80f142459397108a644e9688d6","formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"### lightgbm","metadata":{"cell_id":"eb49b33e47d3432d8b883f2df2c081c6","formattedRanges":[],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"metrics = {}\nfor n_estimators in [3, 5, 10, 15, 30, 50, 100, 250]:\n    for max_depth in [4, 8, 12, 16, 20]:\n        for eta in [0.01, 0.05, 0.1]:\n            start_time = time.time()\n            model = LGBMClassifier(max_depth=max_depth, n_estimators=n_estimators, eta=eta )\n            model.fit(X_train,y_train);\n            \n            train_pred = model.predict_proba(X_train)[:, 1]\n            test_pred = model.predict_proba(X_validation)[:, 1]\n\n            metrics['LGBM_'+ str(n_estimators)+'_'+str(max_depth)] = {\n                'Learning_Rate': eta,\n                'Train_Gini': 2*roc_auc_score(y_train, train_pred)-1,\n                'Test_Gini': 2*roc_auc_score(y_validation, test_pred)-1,\n                'Run_Time': time.time() - start_time\n                }\n\nmetrics_LGBM = pd.DataFrame.from_dict(metrics, orient='index',columns=['Learning_Rate', 'Run_Time', 'Train_Gini', 'Test_Gini'])\nmetrics_LGBM['delta'] = (metrics_LGBM.Test_Gini - metrics_LGBM.Train_Gini) / metrics_LGBM.Train_Gini\nmetrics_LGBM","metadata":{"cell_id":"69ddc8f6800e48b4b43597684c4f0370","source_hash":"2094c08e","execution_start":1684095066369,"execution_millis":140277,"deepnote_table_state":{"sortBy":[{"id":"delta","type":"asc"}],"filters":[],"pageSize":10,"pageIndex":0},"deepnote_table_loading":false,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.01 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.05 will be ignored. Current value: learning_rate=0.1\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n[LightGBM] [Warning] learning_rate is set=0.1, eta=0.1 will be ignored. Current value: learning_rate=0.1\n","output_type":"stream"},{"output_type":"execute_result","execution_count":12,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":5,"row_count":40,"columns":[{"name":"Learning_Rate","dtype":"float64","stats":{"unique_count":1,"nan_count":0,"min":"0.1","max":"0.1","histogram":[{"bin_start":-0.4,"bin_end":-0.30000000000000004,"count":0},{"bin_start":-0.30000000000000004,"bin_end":-0.2,"count":0},{"bin_start":-0.2,"bin_end":-0.09999999999999998,"count":0},{"bin_start":-0.09999999999999998,"bin_end":0,"count":0},{"bin_start":0,"bin_end":0.09999999999999998,"count":0},{"bin_start":0.09999999999999998,"bin_end":0.20000000000000007,"count":40},{"bin_start":0.20000000000000007,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6,"count":0}]}},{"name":"Run_Time","dtype":"float64","stats":{"unique_count":40,"nan_count":0,"min":"0.37938952445983887","max":"4.6034557819366455","histogram":[{"bin_start":0.37938952445983887,"bin_end":0.8017961502075195,"count":19},{"bin_start":0.8017961502075195,"bin_end":1.2242027759552,"count":9},{"bin_start":1.2242027759552,"bin_end":1.646609401702881,"count":6},{"bin_start":1.646609401702881,"bin_end":2.0690160274505613,"count":1},{"bin_start":2.0690160274505613,"bin_end":2.491422653198242,"count":0},{"bin_start":2.491422653198242,"bin_end":2.913829278945923,"count":2},{"bin_start":2.913829278945923,"bin_end":3.3362359046936034,"count":2},{"bin_start":3.3362359046936034,"bin_end":3.7586425304412843,"count":0},{"bin_start":3.7586425304412843,"bin_end":4.1810491561889656,"count":0},{"bin_start":4.1810491561889656,"bin_end":4.6034557819366455,"count":1}]}},{"name":"Train_Gini","dtype":"float64","stats":{"unique_count":31,"nan_count":0,"min":"0.7537255993083734","max":"0.9568834546116491","histogram":[{"bin_start":0.7537255993083734,"bin_end":0.7740413848387009,"count":2},{"bin_start":0.7740413848387009,"bin_end":0.7943571703690285,"count":2},{"bin_start":0.7943571703690285,"bin_end":0.8146729558993561,"count":5},{"bin_start":0.8146729558993561,"bin_end":0.8349887414296837,"count":8},{"bin_start":0.8349887414296837,"bin_end":0.8553045269600112,"count":5},{"bin_start":0.8553045269600112,"bin_end":0.8756203124903388,"count":3},{"bin_start":0.8756203124903388,"bin_end":0.8959360980206664,"count":4},{"bin_start":0.8959360980206664,"bin_end":0.916251883550994,"count":4},{"bin_start":0.916251883550994,"bin_end":0.9365676690813216,"count":3},{"bin_start":0.9365676690813216,"bin_end":0.9568834546116491,"count":4}]}},{"name":"Test_Gini","dtype":"float64","stats":{"unique_count":31,"nan_count":0,"min":"0.7267493533089893","max":"0.8858149750063746","histogram":[{"bin_start":0.7267493533089893,"bin_end":0.7426559154787278,"count":2},{"bin_start":0.7426559154787278,"bin_end":0.7585624776484663,"count":1},{"bin_start":0.7585624776484663,"bin_end":0.7744690398182049,"count":1},{"bin_start":0.7744690398182049,"bin_end":0.7903756019879434,"count":8},{"bin_start":0.7903756019879434,"bin_end":0.806282164157682,"count":5},{"bin_start":0.806282164157682,"bin_end":0.8221887263274205,"count":5},{"bin_start":0.8221887263274205,"bin_end":0.838095288497159,"count":1},{"bin_start":0.838095288497159,"bin_end":0.8540018506668976,"count":4},{"bin_start":0.8540018506668976,"bin_end":0.8699084128366361,"count":6},{"bin_start":0.8699084128366361,"bin_end":0.8858149750063746,"count":7}]}},{"name":"delta","dtype":"float64","stats":{"unique_count":31,"nan_count":0,"min":"-0.07518451189361541","max":"-0.029686858157519754","histogram":[{"bin_start":-0.07518451189361541,"bin_end":-0.07063474652000584,"count":4},{"bin_start":-0.07063474652000584,"bin_end":-0.06608498114639628,"count":0},{"bin_start":-0.06608498114639628,"bin_end":-0.061535215772786714,"count":0},{"bin_start":-0.061535215772786714,"bin_end":-0.05698545039917715,"count":0},{"bin_start":-0.05698545039917715,"bin_end":-0.052435685025567585,"count":1},{"bin_start":-0.052435685025567585,"bin_end":-0.047885919651958014,"count":3},{"bin_start":-0.047885919651958014,"bin_end":-0.04333615427834845,"count":1},{"bin_start":-0.04333615427834845,"bin_end":-0.038786388904738886,"count":3},{"bin_start":-0.038786388904738886,"bin_end":-0.03423662353112932,"count":14},{"bin_start":-0.03423662353112932,"bin_end":-0.029686858157519754,"count":14}]}},{"name":"_deepnote_index_column","dtype":"object"}],"rows":[{"Learning_Rate":"0.1","Run_Time":"2.901623010635376","Train_Gini":"0.9568834546116491","Test_Gini":"0.8849406391375958","delta":"-0.07518451189361541","_deepnote_index_column":"LGBM_250_20"},{"Learning_Rate":"0.1","Run_Time":"2.8079915046691895","Train_Gini":"0.9549780266023049","Test_Gini":"0.8843463088496839","delta":"-0.07396161564462381","_deepnote_index_column":"LGBM_250_12"},{"Learning_Rate":"0.1","Run_Time":"4.6034557819366455","Train_Gini":"0.9526232523392768","Test_Gini":"0.8823466584557353","delta":"-0.07377165496534872","_deepnote_index_column":"LGBM_250_8"},{"Learning_Rate":"0.1","Run_Time":"3.097162961959839","Train_Gini":"0.9557161858269674","Test_Gini":"0.8858149750063746","delta":"-0.07314013496601844","_deepnote_index_column":"LGBM_250_16"},{"Learning_Rate":"0.1","Run_Time":"1.323939323425293","Train_Gini":"0.9211865598384557","Test_Gini":"0.8726527882686321","delta":"-0.052686148154761046","_deepnote_index_column":"LGBM_100_12"},{"Learning_Rate":"0.1","Run_Time":"1.516779899597168","Train_Gini":"0.9219721901856401","Test_Gini":"0.8742574479720444","delta":"-0.05175290829974851","_deepnote_index_column":"LGBM_100_16"},{"Learning_Rate":"0.1","Run_Time":"1.4175031185150146","Train_Gini":"0.9221886326083548","Test_Gini":"0.8747590845453277","delta":"-0.05143150369233626","_deepnote_index_column":"LGBM_100_20"},{"Learning_Rate":"0.1","Run_Time":"1.4010655879974365","Train_Gini":"0.9161061895404228","Test_Gini":"0.8697119278207834","delta":"-0.05064288643537455","_deepnote_index_column":"LGBM_100_8"},{"Learning_Rate":"0.1","Run_Time":"1.9299085140228271","Train_Gini":"0.9021088715206362","Test_Gini":"0.8592405850929903","delta":"-0.04752008075852884","_deepnote_index_column":"LGBM_250_4"},{"Learning_Rate":"0.1","Run_Time":"0.8878593444824219","Train_Gini":"0.8948301648941375","Test_Gini":"0.8589604191423748","delta":"-0.040085534841135216","_deepnote_index_column":"LGBM_50_12"}]},"text/plain":"             Learning_Rate  Run_Time  Train_Gini  Test_Gini     delta\nLGBM_3_4               0.1  0.496893    0.753726   0.726749 -0.035791\nLGBM_3_8               0.1  0.379390    0.807861   0.778629 -0.036184\nLGBM_3_12              0.1  0.404497    0.808028   0.779264 -0.035597\nLGBM_3_16              0.1  0.490969    0.808028   0.779264 -0.035597\nLGBM_3_20              0.1  0.415095    0.808028   0.779264 -0.035597\nLGBM_5_4               0.1  0.679349    0.759821   0.734338 -0.033538\nLGBM_5_8               0.1  0.487319    0.811814   0.782191 -0.036490\nLGBM_5_12              0.1  0.517357    0.815731   0.787170 -0.035013\nLGBM_5_16              0.1  0.804949    0.815731   0.787170 -0.035013\nLGBM_5_20              0.1  0.497945    0.815731   0.787170 -0.035013\nLGBM_10_4              0.1  0.599765    0.779857   0.755192 -0.031627\nLGBM_10_8              0.1  0.710349    0.831937   0.803880 -0.033725\nLGBM_10_12             0.1  0.711556    0.833868   0.805338 -0.034214\nLGBM_10_16             0.1  0.819357    0.833868   0.805338 -0.034214\nLGBM_10_20             0.1  0.492331    0.833868   0.805338 -0.034214\nLGBM_15_4              0.1  0.602211    0.793396   0.769843 -0.029687\nLGBM_15_8              0.1  1.022689    0.850066   0.822075 -0.032928\nLGBM_15_12             0.1  1.574314    0.848641   0.819696 -0.034107\nLGBM_15_16             0.1  0.746789    0.848641   0.819696 -0.034107\nLGBM_15_20             0.1  1.372363    0.848641   0.819696 -0.034107\nLGBM_30_4              0.1  1.010958    0.826610   0.801550 -0.030317\nLGBM_30_8              0.1  3.046281    0.874339   0.844480 -0.034151\nLGBM_30_12             0.1  0.788978    0.875587   0.845589 -0.034260\nLGBM_30_16             0.1  0.686311    0.876334   0.846068 -0.034537\nLGBM_30_20             0.1  0.602349    0.876334   0.846068 -0.034537\nLGBM_50_4              0.1  0.548554    0.841772   0.813474 -0.033616\nLGBM_50_8              0.1  0.873566    0.889195   0.855834 -0.037518\nLGBM_50_12             0.1  0.887859    0.894830   0.858960 -0.040086\nLGBM_50_16             0.1  0.902195    0.897482   0.862047 -0.039483\nLGBM_50_20             0.1  0.820702    0.896625   0.861297 -0.039402\nLGBM_100_4             0.1  0.982131    0.861375   0.829709 -0.036762\nLGBM_100_8             0.1  1.401066    0.916106   0.869712 -0.050643\nLGBM_100_12            0.1  1.323939    0.921187   0.872653 -0.052686\nLGBM_100_16            0.1  1.516780    0.921972   0.874257 -0.051753\nLGBM_100_20            0.1  1.417503    0.922189   0.874759 -0.051432\nLGBM_250_4             0.1  1.929909    0.902109   0.859241 -0.047520\nLGBM_250_8             0.1  4.603456    0.952623   0.882347 -0.073772\nLGBM_250_12            0.1  2.807992    0.954978   0.884346 -0.073962\nLGBM_250_16            0.1  3.097163    0.955716   0.885815 -0.073140\nLGBM_250_20            0.1  2.901623    0.956883   0.884941 -0.075185","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Learning_Rate</th>\n      <th>Run_Time</th>\n      <th>Train_Gini</th>\n      <th>Test_Gini</th>\n      <th>delta</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LGBM_3_4</th>\n      <td>0.1</td>\n      <td>0.496893</td>\n      <td>0.753726</td>\n      <td>0.726749</td>\n      <td>-0.035791</td>\n    </tr>\n    <tr>\n      <th>LGBM_3_8</th>\n      <td>0.1</td>\n      <td>0.379390</td>\n      <td>0.807861</td>\n      <td>0.778629</td>\n      <td>-0.036184</td>\n    </tr>\n    <tr>\n      <th>LGBM_3_12</th>\n      <td>0.1</td>\n      <td>0.404497</td>\n      <td>0.808028</td>\n      <td>0.779264</td>\n      <td>-0.035597</td>\n    </tr>\n    <tr>\n      <th>LGBM_3_16</th>\n      <td>0.1</td>\n      <td>0.490969</td>\n      <td>0.808028</td>\n      <td>0.779264</td>\n      <td>-0.035597</td>\n    </tr>\n    <tr>\n      <th>LGBM_3_20</th>\n      <td>0.1</td>\n      <td>0.415095</td>\n      <td>0.808028</td>\n      <td>0.779264</td>\n      <td>-0.035597</td>\n    </tr>\n    <tr>\n      <th>LGBM_5_4</th>\n      <td>0.1</td>\n      <td>0.679349</td>\n      <td>0.759821</td>\n      <td>0.734338</td>\n      <td>-0.033538</td>\n    </tr>\n    <tr>\n      <th>LGBM_5_8</th>\n      <td>0.1</td>\n      <td>0.487319</td>\n      <td>0.811814</td>\n      <td>0.782191</td>\n      <td>-0.036490</td>\n    </tr>\n    <tr>\n      <th>LGBM_5_12</th>\n      <td>0.1</td>\n      <td>0.517357</td>\n      <td>0.815731</td>\n      <td>0.787170</td>\n      <td>-0.035013</td>\n    </tr>\n    <tr>\n      <th>LGBM_5_16</th>\n      <td>0.1</td>\n      <td>0.804949</td>\n      <td>0.815731</td>\n      <td>0.787170</td>\n      <td>-0.035013</td>\n    </tr>\n    <tr>\n      <th>LGBM_5_20</th>\n      <td>0.1</td>\n      <td>0.497945</td>\n      <td>0.815731</td>\n      <td>0.787170</td>\n      <td>-0.035013</td>\n    </tr>\n    <tr>\n      <th>LGBM_10_4</th>\n      <td>0.1</td>\n      <td>0.599765</td>\n      <td>0.779857</td>\n      <td>0.755192</td>\n      <td>-0.031627</td>\n    </tr>\n    <tr>\n      <th>LGBM_10_8</th>\n      <td>0.1</td>\n      <td>0.710349</td>\n      <td>0.831937</td>\n      <td>0.803880</td>\n      <td>-0.033725</td>\n    </tr>\n    <tr>\n      <th>LGBM_10_12</th>\n      <td>0.1</td>\n      <td>0.711556</td>\n      <td>0.833868</td>\n      <td>0.805338</td>\n      <td>-0.034214</td>\n    </tr>\n    <tr>\n      <th>LGBM_10_16</th>\n      <td>0.1</td>\n      <td>0.819357</td>\n      <td>0.833868</td>\n      <td>0.805338</td>\n      <td>-0.034214</td>\n    </tr>\n    <tr>\n      <th>LGBM_10_20</th>\n      <td>0.1</td>\n      <td>0.492331</td>\n      <td>0.833868</td>\n      <td>0.805338</td>\n      <td>-0.034214</td>\n    </tr>\n    <tr>\n      <th>LGBM_15_4</th>\n      <td>0.1</td>\n      <td>0.602211</td>\n      <td>0.793396</td>\n      <td>0.769843</td>\n      <td>-0.029687</td>\n    </tr>\n    <tr>\n      <th>LGBM_15_8</th>\n      <td>0.1</td>\n      <td>1.022689</td>\n      <td>0.850066</td>\n      <td>0.822075</td>\n      <td>-0.032928</td>\n    </tr>\n    <tr>\n      <th>LGBM_15_12</th>\n      <td>0.1</td>\n      <td>1.574314</td>\n      <td>0.848641</td>\n      <td>0.819696</td>\n      <td>-0.034107</td>\n    </tr>\n    <tr>\n      <th>LGBM_15_16</th>\n      <td>0.1</td>\n      <td>0.746789</td>\n      <td>0.848641</td>\n      <td>0.819696</td>\n      <td>-0.034107</td>\n    </tr>\n    <tr>\n      <th>LGBM_15_20</th>\n      <td>0.1</td>\n      <td>1.372363</td>\n      <td>0.848641</td>\n      <td>0.819696</td>\n      <td>-0.034107</td>\n    </tr>\n    <tr>\n      <th>LGBM_30_4</th>\n      <td>0.1</td>\n      <td>1.010958</td>\n      <td>0.826610</td>\n      <td>0.801550</td>\n      <td>-0.030317</td>\n    </tr>\n    <tr>\n      <th>LGBM_30_8</th>\n      <td>0.1</td>\n      <td>3.046281</td>\n      <td>0.874339</td>\n      <td>0.844480</td>\n      <td>-0.034151</td>\n    </tr>\n    <tr>\n      <th>LGBM_30_12</th>\n      <td>0.1</td>\n      <td>0.788978</td>\n      <td>0.875587</td>\n      <td>0.845589</td>\n      <td>-0.034260</td>\n    </tr>\n    <tr>\n      <th>LGBM_30_16</th>\n      <td>0.1</td>\n      <td>0.686311</td>\n      <td>0.876334</td>\n      <td>0.846068</td>\n      <td>-0.034537</td>\n    </tr>\n    <tr>\n      <th>LGBM_30_20</th>\n      <td>0.1</td>\n      <td>0.602349</td>\n      <td>0.876334</td>\n      <td>0.846068</td>\n      <td>-0.034537</td>\n    </tr>\n    <tr>\n      <th>LGBM_50_4</th>\n      <td>0.1</td>\n      <td>0.548554</td>\n      <td>0.841772</td>\n      <td>0.813474</td>\n      <td>-0.033616</td>\n    </tr>\n    <tr>\n      <th>LGBM_50_8</th>\n      <td>0.1</td>\n      <td>0.873566</td>\n      <td>0.889195</td>\n      <td>0.855834</td>\n      <td>-0.037518</td>\n    </tr>\n    <tr>\n      <th>LGBM_50_12</th>\n      <td>0.1</td>\n      <td>0.887859</td>\n      <td>0.894830</td>\n      <td>0.858960</td>\n      <td>-0.040086</td>\n    </tr>\n    <tr>\n      <th>LGBM_50_16</th>\n      <td>0.1</td>\n      <td>0.902195</td>\n      <td>0.897482</td>\n      <td>0.862047</td>\n      <td>-0.039483</td>\n    </tr>\n    <tr>\n      <th>LGBM_50_20</th>\n      <td>0.1</td>\n      <td>0.820702</td>\n      <td>0.896625</td>\n      <td>0.861297</td>\n      <td>-0.039402</td>\n    </tr>\n    <tr>\n      <th>LGBM_100_4</th>\n      <td>0.1</td>\n      <td>0.982131</td>\n      <td>0.861375</td>\n      <td>0.829709</td>\n      <td>-0.036762</td>\n    </tr>\n    <tr>\n      <th>LGBM_100_8</th>\n      <td>0.1</td>\n      <td>1.401066</td>\n      <td>0.916106</td>\n      <td>0.869712</td>\n      <td>-0.050643</td>\n    </tr>\n    <tr>\n      <th>LGBM_100_12</th>\n      <td>0.1</td>\n      <td>1.323939</td>\n      <td>0.921187</td>\n      <td>0.872653</td>\n      <td>-0.052686</td>\n    </tr>\n    <tr>\n      <th>LGBM_100_16</th>\n      <td>0.1</td>\n      <td>1.516780</td>\n      <td>0.921972</td>\n      <td>0.874257</td>\n      <td>-0.051753</td>\n    </tr>\n    <tr>\n      <th>LGBM_100_20</th>\n      <td>0.1</td>\n      <td>1.417503</td>\n      <td>0.922189</td>\n      <td>0.874759</td>\n      <td>-0.051432</td>\n    </tr>\n    <tr>\n      <th>LGBM_250_4</th>\n      <td>0.1</td>\n      <td>1.929909</td>\n      <td>0.902109</td>\n      <td>0.859241</td>\n      <td>-0.047520</td>\n    </tr>\n    <tr>\n      <th>LGBM_250_8</th>\n      <td>0.1</td>\n      <td>4.603456</td>\n      <td>0.952623</td>\n      <td>0.882347</td>\n      <td>-0.073772</td>\n    </tr>\n    <tr>\n      <th>LGBM_250_12</th>\n      <td>0.1</td>\n      <td>2.807992</td>\n      <td>0.954978</td>\n      <td>0.884346</td>\n      <td>-0.073962</td>\n    </tr>\n    <tr>\n      <th>LGBM_250_16</th>\n      <td>0.1</td>\n      <td>3.097163</td>\n      <td>0.955716</td>\n      <td>0.885815</td>\n      <td>-0.073140</td>\n    </tr>\n    <tr>\n      <th>LGBM_250_20</th>\n      <td>0.1</td>\n      <td>2.901623</td>\n      <td>0.956883</td>\n      <td>0.884941</td>\n      <td>-0.075185</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"aqui tb hay modelos buenardos","metadata":{"cell_id":"3126d62cbfd34d3ab09d4bf7a5c4c0ab","formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"## shap random forest 30,12","metadata":{"cell_id":"659e9d16c8b9431aae2582cfd8692f76","formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"montamos el modelito","metadata":{"cell_id":"962425d58ca0492793573ed9741bcfc9","formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"code","source":"metrics = {}\n\nstart_time = time.time()\nrf = RandomForestClassifier(n_estimators = 30, max_depth = 12, max_features = 'sqrt')\nrf.fit(X_train, y_train);\n\ntrain_pred = rf.predict_proba(X_train)[:, 1]\ntest_pred = rf.predict_proba(X_validation)[:, 1]\n\nmetrics['RF_30_12'] = {\n    'Train_Gini': 2*roc_auc_score(y_train, train_pred)-1,\n    'Test_Gini': 2*roc_auc_score(y_validation, test_pred)-1,\n    'Run_Time': time.time() - start_time\n    }\n\nmetrics_RF = pd.DataFrame.from_dict(metrics, orient='index',columns=['Run_Time', 'Train_Gini', 'Test_Gini'])\nmetrics_RF['delta'] = (metrics_RF.Test_Gini - metrics_RF.Train_Gini) / metrics_RF.Train_Gini\nmetrics_RF","metadata":{"cell_id":"7e41be2682b341fba4977aa8bc6ae547","source_hash":"fbd45f83","execution_start":1684164329278,"execution_millis":587,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_88/690244135.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  rf.fit(X_train, y_train);\n","output_type":"stream"},{"output_type":"execute_result","execution_count":10,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":4,"row_count":1,"columns":[{"name":"Run_Time","dtype":"float64","stats":{"unique_count":1,"nan_count":0,"min":"0.5576071739196777","max":"0.5576071739196777","histogram":[{"bin_start":0.057607173919677734,"bin_end":0.15760717391967774,"count":0},{"bin_start":0.15760717391967774,"bin_end":0.25760717391967775,"count":0},{"bin_start":0.25760717391967775,"bin_end":0.3576071739196778,"count":0},{"bin_start":0.3576071739196778,"bin_end":0.45760717391967776,"count":0},{"bin_start":0.45760717391967776,"bin_end":0.5576071739196777,"count":0},{"bin_start":0.5576071739196777,"bin_end":0.6576071739196778,"count":1},{"bin_start":0.6576071739196778,"bin_end":0.7576071739196778,"count":0},{"bin_start":0.7576071739196778,"bin_end":0.8576071739196778,"count":0},{"bin_start":0.8576071739196778,"bin_end":0.9576071739196778,"count":0},{"bin_start":0.9576071739196778,"bin_end":1.0576071739196777,"count":0}]}},{"name":"Train_Gini","dtype":"float64","stats":{"unique_count":1,"nan_count":0,"min":"0.91135327251414","max":"0.91135327251414","histogram":[{"bin_start":0.41135327251414,"bin_end":0.51135327251414,"count":0},{"bin_start":0.51135327251414,"bin_end":0.61135327251414,"count":0},{"bin_start":0.61135327251414,"bin_end":0.71135327251414,"count":0},{"bin_start":0.71135327251414,"bin_end":0.81135327251414,"count":0},{"bin_start":0.81135327251414,"bin_end":0.91135327251414,"count":0},{"bin_start":0.91135327251414,"bin_end":1.01135327251414,"count":1},{"bin_start":1.01135327251414,"bin_end":1.11135327251414,"count":0},{"bin_start":1.11135327251414,"bin_end":1.21135327251414,"count":0},{"bin_start":1.21135327251414,"bin_end":1.3113532725141401,"count":0},{"bin_start":1.3113532725141401,"bin_end":1.41135327251414,"count":0}]}},{"name":"Test_Gini","dtype":"float64","stats":{"unique_count":1,"nan_count":0,"min":"0.8535881929376368","max":"0.8535881929376368","histogram":[{"bin_start":0.35358819293763677,"bin_end":0.45358819293763675,"count":0},{"bin_start":0.45358819293763675,"bin_end":0.5535881929376367,"count":0},{"bin_start":0.5535881929376367,"bin_end":0.6535881929376368,"count":0},{"bin_start":0.6535881929376368,"bin_end":0.7535881929376368,"count":0},{"bin_start":0.7535881929376368,"bin_end":0.8535881929376368,"count":0},{"bin_start":0.8535881929376368,"bin_end":0.9535881929376369,"count":1},{"bin_start":0.9535881929376369,"bin_end":1.053588192937637,"count":0},{"bin_start":1.053588192937637,"bin_end":1.1535881929376368,"count":0},{"bin_start":1.1535881929376368,"bin_end":1.2535881929376367,"count":0},{"bin_start":1.2535881929376367,"bin_end":1.3535881929376368,"count":0}]}},{"name":"delta","dtype":"float64","stats":{"unique_count":1,"nan_count":0,"min":"-0.06338385049866267","max":"-0.06338385049866267","histogram":[{"bin_start":-0.5633838504986627,"bin_end":-0.4633838504986627,"count":0},{"bin_start":-0.4633838504986627,"bin_end":-0.3633838504986627,"count":0},{"bin_start":-0.3633838504986627,"bin_end":-0.26338385049866264,"count":0},{"bin_start":-0.26338385049866264,"bin_end":-0.16338385049866266,"count":0},{"bin_start":-0.16338385049866266,"bin_end":-0.06338385049866269,"count":0},{"bin_start":-0.06338385049866269,"bin_end":0.0366161495013374,"count":1},{"bin_start":0.0366161495013374,"bin_end":0.13661614950133738,"count":0},{"bin_start":0.13661614950133738,"bin_end":0.23661614950133736,"count":0},{"bin_start":0.23661614950133736,"bin_end":0.33661614950133734,"count":0},{"bin_start":0.33661614950133734,"bin_end":0.4366161495013373,"count":0}]}},{"name":"_deepnote_index_column","dtype":"object"}],"rows":[{"Run_Time":"0.5576071739196777","Train_Gini":"0.91135327251414","Test_Gini":"0.8535881929376368","delta":"-0.06338385049866267","_deepnote_index_column":"RF_30_12"}]},"text/plain":"          Run_Time  Train_Gini  Test_Gini     delta\nRF_30_12  0.557607    0.911353   0.853588 -0.063384","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Run_Time</th>\n      <th>Train_Gini</th>\n      <th>Test_Gini</th>\n      <th>delta</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>RF_30_12</th>\n      <td>0.557607</td>\n      <td>0.911353</td>\n      <td>0.853588</td>\n      <td>-0.063384</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"metricas con los datos de test","metadata":{"cell_id":"c6146527e1844e35a33da3a13edc9873","formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"code","source":"testreal_pred = rf.predict_proba(X_test)[:, 1]\nmetrics2 = {}\nmetrics2['RF_30_12'] = {\n    'Train_Gini': 2*roc_auc_score(y_train, train_pred)-1,\n    'TestReal_Gini': 2*roc_auc_score(y_test, testreal_pred)-1,\n    }\n\nmetrics2_RF = pd.DataFrame.from_dict(metrics2, orient='index',columns=['Train_Gini', 'TestReal_Gini'])\nmetrics2_RF['delta'] = (metrics2_RF.TestReal_Gini - metrics2_RF.Train_Gini) / metrics2_RF.Train_Gini\nmetrics2_RF","metadata":{"cell_id":"e80f89c53ba8483c9f0ae91bb08a57e5","source_hash":"81d3656e","execution_start":1684164616636,"execution_millis":72,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":3,"row_count":1,"columns":[{"name":"Train_Gini","dtype":"float64","stats":{"unique_count":1,"nan_count":0,"min":"0.91135327251414","max":"0.91135327251414","histogram":[{"bin_start":0.41135327251414,"bin_end":0.51135327251414,"count":0},{"bin_start":0.51135327251414,"bin_end":0.61135327251414,"count":0},{"bin_start":0.61135327251414,"bin_end":0.71135327251414,"count":0},{"bin_start":0.71135327251414,"bin_end":0.81135327251414,"count":0},{"bin_start":0.81135327251414,"bin_end":0.91135327251414,"count":0},{"bin_start":0.91135327251414,"bin_end":1.01135327251414,"count":1},{"bin_start":1.01135327251414,"bin_end":1.11135327251414,"count":0},{"bin_start":1.11135327251414,"bin_end":1.21135327251414,"count":0},{"bin_start":1.21135327251414,"bin_end":1.3113532725141401,"count":0},{"bin_start":1.3113532725141401,"bin_end":1.41135327251414,"count":0}]}},{"name":"TestReal_Gini","dtype":"float64","stats":{"unique_count":1,"nan_count":0,"min":"0.8558769067013845","max":"0.8558769067013845","histogram":[{"bin_start":0.3558769067013845,"bin_end":0.4558769067013845,"count":0},{"bin_start":0.4558769067013845,"bin_end":0.5558769067013845,"count":0},{"bin_start":0.5558769067013845,"bin_end":0.6558769067013845,"count":0},{"bin_start":0.6558769067013845,"bin_end":0.7558769067013845,"count":0},{"bin_start":0.7558769067013845,"bin_end":0.8558769067013845,"count":0},{"bin_start":0.8558769067013845,"bin_end":0.9558769067013846,"count":1},{"bin_start":0.9558769067013846,"bin_end":1.0558769067013847,"count":0},{"bin_start":1.0558769067013847,"bin_end":1.1558769067013845,"count":0},{"bin_start":1.1558769067013845,"bin_end":1.2558769067013844,"count":0},{"bin_start":1.2558769067013844,"bin_end":1.3558769067013845,"count":0}]}},{"name":"delta","dtype":"float64","stats":{"unique_count":1,"nan_count":0,"min":"-0.06087251506730587","max":"-0.06087251506730587","histogram":[{"bin_start":-0.5608725150673058,"bin_end":-0.46087251506730587,"count":0},{"bin_start":-0.46087251506730587,"bin_end":-0.36087251506730583,"count":0},{"bin_start":-0.36087251506730583,"bin_end":-0.2608725150673058,"count":0},{"bin_start":-0.2608725150673058,"bin_end":-0.16087251506730582,"count":0},{"bin_start":-0.16087251506730582,"bin_end":-0.060872515067305843,"count":1},{"bin_start":-0.060872515067305843,"bin_end":0.039127484932694245,"count":0},{"bin_start":0.039127484932694245,"bin_end":0.13912748493269422,"count":0},{"bin_start":0.13912748493269422,"bin_end":0.2391274849326942,"count":0},{"bin_start":0.2391274849326942,"bin_end":0.3391274849326942,"count":0},{"bin_start":0.3391274849326942,"bin_end":0.43912748493269416,"count":0}]}},{"name":"_deepnote_index_column","dtype":"object"}],"rows":[{"Train_Gini":"0.91135327251414","TestReal_Gini":"0.8558769067013845","delta":"-0.06087251506730587","_deepnote_index_column":"RF_30_12"}]},"text/plain":"          Train_Gini  TestReal_Gini     delta\nRF_30_12    0.911353       0.855877 -0.060873","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Train_Gini</th>\n      <th>TestReal_Gini</th>\n      <th>delta</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>RF_30_12</th>\n      <td>0.911353</td>\n      <td>0.855877</td>\n      <td>-0.060873</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"efectivamente va como esperábamos","metadata":{"cell_id":"73a7c691d6f24f7e9c93b4e0a10532f6","formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"code","source":"import shap\n\nexplainer = shap.Explainer(rf)\nshap_values = explainer(X_train)\n\nshap.summary_plot(shap_values, X_train, feature_names=X_train.columns)","metadata":{"cell_id":"4a42be40412d447faa2a4476b0c71848","source_hash":"89966662","execution_start":1684164747395,"execution_millis":184771,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.8/site-packages/shap/utils/_clustering.py:35: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _pt_shuffle_rec(i, indexes, index_mask, partition_tree, M, pos):\n/opt/conda/lib/python3.8/site-packages/shap/utils/_clustering.py:54: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def delta_minimization_order(all_masks, max_swap_size=100, num_passes=2):\n/opt/conda/lib/python3.8/site-packages/shap/utils/_clustering.py:63: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _reverse_window(order, start, length):\n/opt/conda/lib/python3.8/site-packages/shap/utils/_clustering.py:69: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _reverse_window_score_gain(masks, order, start, length):\n/opt/conda/lib/python3.8/site-packages/shap/utils/_clustering.py:77: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _mask_delta_score(m1, m2):\n/opt/conda/lib/python3.8/site-packages/shap/links.py:5: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def identity(x):\n/opt/conda/lib/python3.8/site-packages/shap/links.py:10: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _identity_inverse(x):\n/opt/conda/lib/python3.8/site-packages/shap/links.py:15: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def logit(x):\n/opt/conda/lib/python3.8/site-packages/shap/links.py:20: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _logit_inverse(x):\n/opt/conda/lib/python3.8/site-packages/shap/utils/_masked_model.py:363: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _build_fixed_single_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n/opt/conda/lib/python3.8/site-packages/shap/utils/_masked_model.py:385: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _build_fixed_multi_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n/opt/conda/lib/python3.8/site-packages/shap/utils/_masked_model.py:428: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _init_masks(cluster_matrix, M, indices_row_pos, indptr):\n/opt/conda/lib/python3.8/site-packages/shap/utils/_masked_model.py:439: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _rec_fill_masks(cluster_matrix, indices_row_pos, indptr, indices, M, ind):\n/opt/conda/lib/python3.8/site-packages/shap/maskers/_tabular.py:186: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _single_delta_mask(dind, masked_inputs, last_mask, data, x, noop_code):\n/opt/conda/lib/python3.8/site-packages/shap/maskers/_tabular.py:197: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _delta_masking(masks, x, curr_delta_inds, varying_rows_out,\n/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n/opt/conda/lib/python3.8/site-packages/shap/maskers/_image.py:175: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _jit_build_partition_tree(xmin, xmax, ymin, ymax, zmin, zmax, total_ywidth, total_zwidth, M, clustering, q):\n/opt/conda/lib/python3.8/site-packages/shap/explainers/_partition.py:676: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def lower_credit(i, value, M, values, clustering):\nThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\nThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\nNo data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n","output_type":"stream"},{"data":{"text/plain":"<Figure size 1150x660 with 2 Axes>","image/png":"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\n"},"metadata":{"image/png":{"width":455,"height":680}},"output_type":"display_data"}],"execution_count":14},{"cell_type":"markdown","source":"tampoco funciona el shap","metadata":{"cell_id":"df5d1797adcb4908b7614a0626852807","formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"code","source":"","metadata":{"cell_id":"757e0e4f37f34d018a6e4e38d41e164e","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ca563382-6f70-4aa4-99f1-efca4704b6b0' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"e8f79db8fff1483aa7dd5453efd1131f","deepnote_execution_queue":[]}}